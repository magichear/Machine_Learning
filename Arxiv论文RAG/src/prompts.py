class Prompts:
    def __init__(self):
        self.identity_q = 'You must reply in English. You are a professional academic assistant specializing in the cs.CL domain. Strictly based on the provided literature information, answer the user\'s query. You may slightly expand and refine the response using existing knowledge, but avoid fabricating information. The response language must be English. Ensure the response is concise and limited to 500 words. Include a citation with the corresponding literature link (like [text](f"https://arxiv.org/abs/{{id}}")) and adjust the response style based on the temperature parameter (from 0.0 to 1.0). If the temperature is low (e.g., 0.2), provide a strict and precise answer. If the temperature is high (e.g., 0.8), provide a more creative and exploratory answer. And you must reply in English! Do not use Chinese or any other language!'
        self.template_q = """
Temperature: {temperature}
Question: {question}
Relevant Literature: 
{context}

Answer:
"""
        self.identity_e = "你是一个专业的学术助手，专注于cs.CL及其延伸领域。你的任务是从用户的问题中提取关键学术内容，并以关键词的形式表述。注意：你不需要直接回答问题，也不需要扩写问题，而是提取问题中的核心学术概念或主题，并以英文输出（严格输出且仅输出回复）。确保输出适合用于相似性向量查询。"
        self.template_e = """
Query: {query}

Extracted Academic Content:
"""

        self.identity_eval = """你的所有内容都必须使用中文回复！
        
你是一名客观的专家评估员，专注于评估 cs.CL 领域的学术回答，你需要根据提供的标准，对给定的问答对进行评估。请为每个标准提供一个评分（1-5），并简要解释评分原因。评估标准如下：

1. 相关性：回答与用户问题的契合程度如何？
2. 流畅性：回答是否表达清晰、连贯、易于理解？
3. 事实准确性：回答是否严格依据提供的文献信息，且未捏造信息？
4. 信息完整性：回答是否提供了足够的细节，未遗漏关键点？
5. 冗余度：回答是否避免了不必要的重复或过于冗长的解释？

评估格式（用中文回复）：
1. 相关性：[评分] - [解释]
2. 流畅性：[评分] - [解释]
3. 事实准确性：[评分] - [解释]
4. 信息完整性：[评分] - [解释]
5. 冗余度：[评分] - [解释]

最终评论：
[用中文提供对回答的总体评论，指出优点和需要改进的地方。]
"""
        self.template_eval = """
问答对如下：

```
{qar}
```
"""

        self.questions = [
            "什么是注意力机制？",
            "对比Transformer与RNN在机器翻译中的性能",
            "大语言模型的 “幻觉” 问题本质是语义理解缺陷还是推理过程偏差？如何构建可靠性评估框架？",
            "零样本学习中，提示词工程能否真正激活模型的 “潜在知识”？其理论边界在哪？",
            "小样本场景下，元学习与预训练模型的适应性调整策略如何结合？",
            "预训练模型的 “涌现能力” 是否具有可预测性？如何从理论上解释其突现机制？",
            "大模型的上下文窗口扩展是否会引入 “长距离语义稀释”？如何设计高效的长期依赖建模机制？",
            "句法语义一体化建模中，成分结构与依存结构能否统一表示？",
            "Transformer模型的自注意力机制是否存在 “信息泄露” 风险？如何设计防护措施？",
            "Transformer上的文本分类和基于CNN的图片分类遇到的问题及解决方案的异同？",
            "什么是对抗攻击，常用黑盒文本对抗攻击手段有哪些？",
            "什么是对抗攻击，常用白盒文本对抗攻击手段有哪些？",
            "FGSM对抗攻击方法是否能以及如何迁移到文本对抗攻击领域？",
            "解释一下如何使用BERT生成黑盒对抗攻击样本",
            "低资源语言的形态丰富性（如黏着语）如何影响少样本词义消歧？基于类型学的迁移学习是否有效？",
            "BGE模型如何将文本向量化",
            "在机器翻译中，如何处理专有名词和术语的翻译问题？",
            "在机器翻译中，如何提高对长句和复杂句的翻译质量？",
            "如何构建一个高效的文本语义相似度计算模型？",
            "在多语言对话系统中，如何实现语言的无缝切换和交流？",
            "在诗歌生成任务中，如何让机器生成符合诗歌格律和意境的作品？",
            "在文本纠错任务中，如何提高对拼写错误、语法错误的检测和纠正能力？",
            "在机器翻译中，如何更好地处理源语言与目标语言之间的语义差异和文化差异？",
            "在文本生成任务中，如何平衡生成文本的多样性、正确性和连贯性？",
            "在对话系统中，如何提高对用户意图的理解准确率并生成更加自然流畅的回复？",
            "如何构建一个鲁棒的文本分类模型，以应对文本数据的噪声和不平衡问题？",
            "如何设计一种能够准确识别文本中隐喻表达的模型，并将其应用于情感分析或文本理解？",
            "针对低资源语言，如何利用迁移学习来提高自然语言处理任务的性能？",
            "在自然语言处理中，如何处理文本数据中的歧义问题？",
            "如何提高对古文字的识别和释读能力？",
            "在文本风格迁移任务中，如何准确地将文本从一种风格转换为另一种风格？",
            "如何利用计算语言学技术对文学作品进行风格分析？",
            "如何设计一种能够准确识别文本中事件的模型？",
            "如何通过计算语言学方法挖掘文学作品中的叙事结构和情节发展？",
            "如何构建一个高效的文本语义相似度计算模型，以支持信息检索和文本匹配？",
            "深度学习中的 “灾难性遗忘” 在 NLP 任务中表现为何种形式？",
            "阅读障碍者的语言处理缺陷能否通过深度学习模型复现？",
            "如何进行代码生成？",
            "语系差异显著的语言（如汉藏语系 vs. 印欧语系）在句法表征上的本质区别如何影响跨语言迁移？",
            "在多语言文本分类任务中，如何利用多任务学习来提高分类性能？",
            "如何区分大语言模型生成文本与人类文本？",
            "对于由多个大模型生成文本与人类文本混合的数据集（数据集仅含两种标签），如何区分出大模型生成的文本？",
            "不同大模型生成文本的检测方法是否存在差异？如何针对性地进行检测？",
            "在大语言模型生成文本检测任务中，如何设计有效的特征提取方法，以区分大模型生成文本与人工编写文本的细微差别？",
            "是否可以利用对抗训练等技术提高大模型生成文本的可检测性，如果可以应该如何实现？",
            "如何构建大规模、高质量的大模型生成文本检测数据集？",
            "如何应对大模型生成文本不断优化带来的检测挑战？",
            "如何构建一个能够自适应不同领域和风格的文本生成模型？",
            "在文本分类任务中，如何处理文本数据中的噪声和异常值，以提高模型的性能与鲁棒性？",
            "什么是知识图谱，如何对文本数据构建知识图谱？",
        ]

    def get_query(self, question, context, temperature=0.2):
        """
        rag核心模板
        """
        return {
            "identity": self.identity_q,
            "template": self.template_q.format(
                temperature=temperature, question=question, context=context
            ),
        }

    def get_extraction(self, query):
        """
        给定一句查询，以cs.CL专家视角提取出核心学术内容
        """
        return {
            "identity": self.identity_e,
            "template": self.template_e.format(query=query),
        }

    def get_eval(self, qar):
        return {
            "identity": self.identity_eval,
            "template": self.template_eval.format(qar=qar),
        }

    def get_questions(self):
        """
        五十个问题，一半来源于豆包与Kimi，另一半来源于本人近期工作
        """
        return self.questions


"""
什么是注意力机制？

对⽐Transformer与RNN在机器翻译中的性能

大语言模型的 “幻觉” 问题本质是语义理解缺陷还是推理过程偏差？如何构建可靠性评估框架？

零样本学习中，提示词工程能否真正激活模型的 “潜在知识”？其理论边界在哪？

小样本场景下，元学习与预训练模型的适应性调整策略如何结合？

预训练模型的 “涌现能力” 是否具有可预测性？如何从理论上解释其突现机制？

大模型的上下文窗口扩展是否会引入 “长距离语义稀释”？如何设计高效的长期依赖建模机制？

句法语义一体化建模中，成分结构与依存结构能否统一表示？

Transformer模型的自注意力机制是否存在 “信息泄露” 风险？如何设计防护措施？

Transformer上的文本分类和基于CNN的图片分类遇到的问题及解决方案的异同？

---

什么是对抗攻击，常用黑盒文本对抗攻击手段有哪些？

什么是对抗攻击，常用白盒文本对抗攻击手段有哪些？

FGSM对抗攻击方法是否能以及如何迁移到文本对抗攻击领域？

解释一下如何使用BERT生成黑盒对抗攻击样本

低资源语言的形态丰富性（如黏着语）如何影响少样本词义消歧？基于类型学的迁移学习是否有效？

BGE模型如何将文本向量化

在机器翻译中，如何处理专有名词和术语的翻译问题？

在机器翻译中，如何提高对长句和复杂句的翻译质量？

如何构建一个高效的文本语义相似度计算模型？

在多语言对话系统中，如何实现语言的无缝切换和交流？

---

在诗歌生成任务中，如何让机器生成符合诗歌格律和意境的作品？

在文本纠错任务中，如何提高对拼写错误、语法错误的检测和纠正能力？

在机器翻译中，如何更好地处理源语言与目标语言之间的语义差异和文化差异？

在文本生成任务中，如何平衡生成文本的多样性、正确性和连贯性？

在对话系统中，如何提高对用户意图的理解准确率并生成更加自然流畅的回复？

如何构建一个鲁棒的文本分类模型，以应对文本数据的噪声和不平衡问题？

如何设计一种能够准确识别文本中隐喻表达的模型，并将其应用于情感分析或文本理解？

针对低资源语言，如何利用迁移学习来提高自然语言处理任务的性能？

在自然语言处理中，如何处理文本数据中的歧义问题？

如何提高对古文字的识别和释读能力？

---

在文本风格迁移任务中，如何准确地将文本从一种风格转换为另一种风格？

如何利用计算语言学技术对文学作品进行风格分析？

如何设计一种能够准确识别文本中事件的模型？

如何通过计算语言学方法挖掘文学作品中的叙事结构和情节发展？

如何构建一个高效的文本语义相似度计算模型，以支持信息检索和文本匹配？

深度学习中的 “灾难性遗忘” 在 NLP 任务中表现为何种形式？

阅读障碍者的语言处理缺陷能否通过深度学习模型复现？

如何进行代码生成？

语系差异显著的语言（如汉藏语系 vs. 印欧语系）在句法表征上的本质区别如何影响跨语言迁移？

在多语言文本分类任务中，如何利用多任务学习来提高分类性能？

---

如何区分大语言模型生成文本与人类文本？

对于由多个大模型生成文本与人类文本混合的数据集（数据集仅含两种标签），如何区分出大模型生成的文本？

不同大模型生成文本的检测方法是否存在差异？如何针对性地进行检测？

在大语言模型生成文本检测任务中，如何设计有效的特征提取方法，以区分大模型生成文本与人工编写文本的细微差别？

是否可以利用对抗训练等技术提高大模型生成文本的可检测性，如果可以应该如何实现？

如何构建大规模、高质量的大模型生成文本检测数据集？

如何应对大模型生成文本不断优化带来的检测挑战？

如何构建一个能够自适应不同领域和风格的文本生成模型？

在文本分类任务中，如何处理文本数据中的噪声和异常值，以提高模型的性能与鲁棒性？

什么是知识图谱，如何对文本数据构建知识图谱？

"""
