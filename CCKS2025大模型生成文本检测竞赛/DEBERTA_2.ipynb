{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GJ73UXQrWuP"
      },
      "source": [
        "### 加载数据集"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFjvB8BGOhdV",
        "outputId": "9f62451d-50f7-40d0-938c-b8e46bbcac27"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import sklearn\n",
        "import transformers\n",
        "\n",
        "!python --version\n",
        "print(f\"os          : {os.name}\")\n",
        "print(f\"torch       : {torch.__version__}\")\n",
        "print(f\"pandas      : {pd.__version__}\")\n",
        "print(f\"matplotlib  : {matplotlib.__version__}\")\n",
        "print(f\"sklearn     : {sklearn.__version__}\")\n",
        "print(f\"transformers: {transformers.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zVNujL7rnacz"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cloning into './models/deberta-v3-base'...\n",
            "Updating files:  62% (5/8)\n",
            "Updating files:  75% (6/8)\n",
            "Updating files:  87% (7/8)\n",
            "Updating files: 100% (8/8)\n",
            "Updating files: 100% (8/8), done.\n",
            "Filtering content:  50% (2/4)\n",
            "Filtering content:  50% (2/4), 356.30 MiB | 9.55 MiB/s\n",
            "Filtering content:  75% (3/4), 356.30 MiB | 9.55 MiB/s\n",
            "Filtering content:  75% (3/4), 1.03 GiB | 15.71 MiB/s \n",
            "Filtering content: 100% (4/4), 1.03 GiB | 15.71 MiB/s\n",
            "Filtering content: 100% (4/4), 1.72 GiB | 25.65 MiB/s\n",
            "Filtering content: 100% (4/4), 1.72 GiB | 25.01 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "# imdb的无监督数据集可以做对比学习或特定领域微调（如果允许）\n",
        "#!git clone https://hf-mirror.com/datasets/stanfordnlp/imdb ./datasets/imdb\n",
        "# !git clone https://hf-mirror.com/datasets/stanfordnlp/sst2 ./datasets/sst2\n",
        "\n",
        "# model  全库\n",
        "!git clone https://hf-mirror.com/microsoft/deberta-v3-base ./models/deberta-v3-base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
            "Collecting sentencepiece\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/85/f4/4ef1a6e0e9dbd8a60780a91df8b7452ada14cfaa0e17b3b8dfa42cecae18/sentencepiece-0.2.0-cp310-cp310-win_amd64.whl (991 kB)\n",
            "     ---------------------------------------- 0.0/991.5 kB ? eta -:--:--\n",
            "     ------------------------------------- 991.5/991.5 kB 11.8 MB/s eta 0:00:00\n",
            "Collecting tiktoken\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/cd/4c/22eb8e9856a2b1808d0a002d171e534eac03f96dbe1161978d7389a59498/tiktoken-0.9.0-cp310-cp310-win_amd64.whl (894 kB)\n",
            "     ---------------------------------------- 0.0/894.0 kB ? eta -:--:--\n",
            "     ------------------------------------- 894.0/894.0 kB 13.7 MB/s eta 0:00:00\n",
            "Requirement already satisfied: regex>=2022.1.18 in d:\\python\\lib\\site-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in d:\\python\\lib\\site-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\python\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\python\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\python\\lib\\site-packages (from requests>=2.26.0->tiktoken) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\python\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2023.5.7)\n",
            "Installing collected packages: sentencepiece, tiktoken\n",
            "Successfully installed sentencepiece-0.2.0 tiktoken-0.9.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -rotobuf (d:\\python\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (d:\\python\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (d:\\python\\lib\\site-packages)\n",
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install sentencepiece tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "K_d1cDKv0IIq",
        "outputId": "a44dd09f-3b02-4184-c749-8b449945f11e"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#import shutil\n",
        "#drive.mount(\"/content/drive/\")\n",
        "#srcC = \"./models/bert-base-uncased/deberta-v3-base-mlm.bin\"\n",
        "#destC = \"/content/drive/MyDrive/deberta-v3-base-mlm.bin\"\n",
        "#shutil.copy(srcC, destC)\n",
        "# shutil.copy(destC, srcC)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uRbpPGFnacz"
      },
      "outputs": [],
      "source": [
        "# IMDB需要\n",
        "#%pip install fastparquet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hx2zk4aSw7OU"
      },
      "outputs": [],
      "source": [
        "#%mkdir datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "BEhf0WoTnac0"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import json\n",
        "import torch\n",
        "import string\n",
        "import random\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import get_linear_schedule_with_warmup,DataCollatorForLanguageModeling\n",
        "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
        "from torch.optim import AdamW   # transformers 里的 AdamW 不再被推荐\n",
        "\n",
        "IMDB_PATH = \"./data/imdb/plain_text/\"\n",
        "IMDB_TRAIN = IMDB_PATH + \"train-00000-of-00001.parquet\"\n",
        "IMDB_TEST = IMDB_PATH + \"test-00000-of-00001.parquet\"\n",
        "IMDB_UNSUPERVISED = IMDB_PATH + \"unsupervised-00000-of-00001.parquet\"   # 无标签数据，可以拿来做语料训练\n",
        "\n",
        "TRAIN_PATH = \"./datasets/train.jsonl\"\n",
        "TEST_PATH = \"./datasets/test.jsonl\"\n",
        "PSEUDO_PATH = \"pseudo.jsonl\"  # 伪标签数据\n",
        "MODEL_PATH = \"./models/deberta-v3-base\"\n",
        "MODEL_E2E_NAME = MODEL_PATH+\"/deberta-v3-base-e2e.bin\"\n",
        "MODEL_PRE_NAME = MODEL_PATH+\"/deberta-v3-base-mlm.bin\"\n",
        "MODEL_PRE_PATH = MODEL_PATH+\"/deberta-v3-base-mlm\"\n",
        "\n",
        "# 分类标签数\n",
        "NUM_LABELS = 2\n",
        "classes= {\n",
        "    1: \"Machine\",\n",
        "    0: \"Human\"\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNvLk_tuwbP4"
      },
      "source": [
        "机器相关配置：队友们在运行前必须先根据机器情况配置此处"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aG2OfuEkwbP4"
      },
      "outputs": [],
      "source": [
        "# 这两项十分消耗显存，参考：colab的T4显卡只能运行 128*128\n",
        "MAX_LENGTH = 32  # 一般不超过512\n",
        "BATCH_SIZE = 32\n",
        "BATCH_SIZE_TEST = BATCH_SIZE << 3 # 测试不会消耗太多资源\n",
        "# 线程数（一般一个运数据，一个跑）\n",
        "NUM_WORKERS = 2\n",
        "# 学习率\n",
        "LEARNING_RATE = 5e-5\n",
        "EPOCHS = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQWRaOnSwbP4",
        "outputId": "557620eb-dda5-4e09-dba5-e113910e293f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "256\n"
          ]
        }
      ],
      "source": [
        "print(BATCH_SIZE << 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2n5-4c_8nac0",
        "outputId": "33dbf4f0-6541-4165-f138-05ca87eef2fa"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi\n",
        "device = torch.device(\"cuda\")\n",
        "print(f\"Using device: {torch.cuda.get_device_name(0)}\")\n",
        "if torch.cuda.get_device_capability(0)[0] >= 7:\n",
        "    print(\"[INFO] 支持混合精度\")\n",
        "else:\n",
        "    print(\"[WARNING] 不支持混合精度\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CudB51zBnac0"
      },
      "source": [
        "### 数据预处理"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qFZG8Wffnac0"
      },
      "outputs": [],
      "source": [
        "def clean_text(text, is_uncased=True):\n",
        "    text = re.sub(r'<.*?>', '', text)                                 # 去除HTML标签\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))  # 去除标点符号\n",
        "    if is_uncased:\n",
        "        #text = text.lower()                                           # 转为小写（注意：uncased模型需要，其余模型不必）\n",
        "        pass\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()                          # 去除多余空格\n",
        "    return text\n",
        "def preprocess_dataset(df, ds_type=\"DETECT\", is_MLM=False):\n",
        "    row_name=\"sentence\" if ds_type == \"SST2\" else \"text\"    # 本次任务与IMDB均为text，仅SST2为sentence\n",
        "    df[\"text\"] = df[row_name].apply(clean_text)\n",
        "    if not is_MLM:\n",
        "        data_list = df[[\"text\", \"label\"]].to_dict(orient=\"records\")\n",
        "        print(df[\"label\"].value_counts(normalize=True))\n",
        "    else:\n",
        "        data_list = df[\"text\"].to_list()\n",
        "    return data_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XiMTeb2nac0",
        "outputId": "06fad565-5ea9-4e84-e2c3-620929532e04"
      },
      "outputs": [],
      "source": [
        "def init_data(is_MLM=False, pseudo=False):\n",
        "    with open(TRAIN_PATH, \"r\", encoding=\"utf-8\") as file:\n",
        "        train_raw = [json.loads(line) for line in file]\n",
        "    with open(TEST_PATH, \"r\", encoding=\"utf-8\") as file:\n",
        "        test_raw = [json.loads(line) for line in file]\n",
        "    if pseudo:\n",
        "        with open(PSEUDO_PATH, \"r\", encoding=\"utf-8\") as file:\n",
        "            pseudo_raw = [json.loads(line) for line in file]\n",
        "        train_raw.extend(pseudo_raw)\n",
        "\n",
        "    train_df = pd.DataFrame(train_raw)\n",
        "    test_df = pd.DataFrame(test_raw)\n",
        "\n",
        "    train_text_lengths = train_df[\"text\"].apply(len)\n",
        "    test_text_lengths = test_df[\"text\"].apply(len)\n",
        "    print(f\"avg train text: {train_text_lengths.mean():.2f}\")\n",
        "    print(f\"avg test text: {test_text_lengths.mean():.2f}\")\n",
        "\n",
        "    print(train_df.head())\n",
        "    print(test_df.head())\n",
        "\n",
        "    train_list_ = preprocess_dataset(train_df)\n",
        "    test_data = preprocess_dataset(test_df, is_MLM=True)\n",
        "\n",
        "    train_processed_lengths = [len(item[\"text\"]) for item in train_list_]\n",
        "    test_processed_lengths = [len(text) for text in test_data]\n",
        "    print(f\"avg train text(final): {sum(train_processed_lengths) / len(train_processed_lengths):.2f}\")\n",
        "    print(f\"avg test text(final): {sum(test_processed_lengths) / len(test_processed_lengths):.2f}\")\n",
        "\n",
        "    labels = [item[\"label\"] for item in train_list_]\n",
        "\n",
        "    # 训练：测试+验证 = 8:2\n",
        "    train_data, valid_data = train_test_split(\n",
        "        train_list_, test_size=0.2, random_state=42, stratify=labels\n",
        "    )\n",
        "\n",
        "    # 无监督训练用不到测试集，把原有的训练集和验证集覆盖，保留正式数据划分好的测试集\n",
        "    if is_MLM:\n",
        "        combined_data = preprocess_dataset(pd.read_parquet(IMDB_UNSUPERVISED), ds_type=\"IMDB\", is_MLM=True)\n",
        "        train_data, valid_data = train_test_split(\n",
        "            combined_data, test_size=0.2, random_state=42\n",
        "        )\n",
        "    random.shuffle(train_data)\n",
        "    random.shuffle(valid_data)\n",
        "\n",
        "    print(f\"训练集长度: {len(train_data)}; 验证集长度: {len(valid_data)}; 测试集长度: {len(test_data)}\")\n",
        "\n",
        "    return train_data, valid_data, test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mEGrKHXnnac0"
      },
      "outputs": [],
      "source": [
        "# data_list是经过预处理的列表，每项包含 text 和 label\n",
        "class DetectDataset(Dataset):\n",
        "    def __init__(self, data_list, tokenizer, max_length=MAX_LENGTH, is_MLM=False):\n",
        "        self.data = data_list\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.is_MLM = is_MLM\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if not self.is_MLM:\n",
        "            text = self.data[idx][\"text\"]\n",
        "        else:\n",
        "            text = self.data[idx]   # MLM 只有一列\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            add_special_tokens=True,    # 加上 [CLS]（开头） 和 [SEP]（结尾），不够的用[PAD]填充\n",
        "            max_length=self.max_length, # 输入序列的最大长度\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,            # 启用截断\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        if not self.is_MLM:\n",
        "            return {key: val.squeeze(0) for key, val in encoding.items()}, torch.tensor(self.data[idx][\"label\"])\n",
        "\n",
        "        return {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "\n",
        "# 这个运行挺快的，就不缓存了\n",
        "def load_data(tokenizer, is_MLM=False):\n",
        "    train_data, val_data, test_data = init_data(is_MLM)\n",
        "    train_dataset = DetectDataset(train_data, tokenizer, is_MLM=is_MLM)\n",
        "    val_dataset = DetectDataset(val_data, tokenizer, is_MLM=is_MLM)\n",
        "    test_dataset = DetectDataset(test_data, tokenizer, is_MLM=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE_TEST)\n",
        "\n",
        "    # 自动处理掩码，随机掩码（默认15%的）token并使用原始input_ids作为labels（非掩码位置设为-100以忽略损失）\n",
        "    collate_fn = None if not is_MLM else DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE_TEST, collate_fn=collate_fn, num_workers=2, pin_memory=True)\n",
        "    # for batch in train_loader:\n",
        "    #    inputs, labels = batch\n",
        "    #    print(\"Inputs:\", inputs)\n",
        "    #    print(\"Labels:\", labels)\n",
        "    #    break\n",
        "\n",
        "    return train_loader, val_loader, test_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdlDDCMTwbP6"
      },
      "source": [
        "### 训练器与测试器\n",
        "\n",
        "在`colab`上训练时每个`batch`都至少输出一条信息，不然会因为长时间无响应而断开连接"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1x0PySoCnac1"
      },
      "outputs": [],
      "source": [
        "class ModelTrainer:\n",
        "    def __init__(self, model, train_loader, val_loader, epochs=3, lr=2e-5, is_MLM=False):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model = model.to(self.device)\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.is_MLM = is_MLM\n",
        "        self.epochs = epochs\n",
        "        self.lr = lr\n",
        "\n",
        "        # AdamW 是加入了权重衰减的Adam\n",
        "        self.optimizer = AdamW(self.model.parameters(), lr=lr)\n",
        "        # 学习率从0增加到设定的最大值然后逐渐线性下降\n",
        "        self.scheduler = get_linear_schedule_with_warmup(\n",
        "            self.optimizer,\n",
        "            num_warmup_steps=2,\n",
        "            num_training_steps=len(train_loader)*epochs\n",
        "        )\n",
        "        self.loss_func = nn.CrossEntropyLoss()\n",
        "        # 拓展：混合精度训练\n",
        "        self.scaler = torch.amp.GradScaler(device=self.device.type)\n",
        "\n",
        "        # 训练记录\n",
        "        self.train_losses, self.val_losses = [], []\n",
        "        self.train_accs, self.val_accs = [], []\n",
        "        self.train_precisions, self.val_precisions = [], []\n",
        "        self.train_recalls, self.val_recalls = [], []\n",
        "        self.train_f1s, self.val_f1s = [], []\n",
        "        self.best_accuracy = 0.0\n",
        "        self.min_loss = float(\"inf\")\n",
        "        self.save_name = MODEL_E2E_NAME\n",
        "        self.bear_cnt = 0\n",
        "        self.epc=1\n",
        "        self.mlm_loss_train = []\n",
        "        self.mlm_loss_valid = []\n",
        "\n",
        "        # print(f\"[DEBUG] train loader length:{len(self.train_loader)}\")\n",
        "\n",
        "    def train(self):\n",
        "        for epoch in range(self.epochs):\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "            # 训练\n",
        "            # print(f\"[DEBUG] train\")\n",
        "            train_loss, train_acc, train_precision, train_recall, train_f1 = self.__train_part()\n",
        "\n",
        "            # 验证\n",
        "            # print(f\"[DEBUG] valid\")\n",
        "            val_loss, val_acc, val_precision, val_recall, val_f1 = self._valid_part()\n",
        "            self.epc+=1\n",
        "\n",
        "            # 保存最佳模型\n",
        "            if not self.is_MLM and val_acc > self.best_accuracy:\n",
        "                self.best_accuracy = val_acc\n",
        "                self.bear_cnt=0\n",
        "                torch.save(self.model.state_dict(), self.save_name)\n",
        "            if val_loss < self.min_loss:\n",
        "                self.min_loss = val_loss\n",
        "                self.bear_cnt = 0\n",
        "            else:\n",
        "                self.bear_cnt += 1\n",
        "                if self.bear_cnt >= 3:\n",
        "                    print(\"[INFO] Early stop\")\n",
        "                    break\n",
        "\n",
        "            print(f\"Epoch {epoch + 1}/{self.epochs}\")\n",
        "            print(\n",
        "                f\"Train Loss: {train_loss:.4f}, \"\n",
        "                f\"Acc: {f'{train_acc:.4f}'             if train_acc       is not None else 'N/A'}, \"\n",
        "                f\"Precision: {f'{train_precision:.4f}' if train_precision is not None else 'N/A'}, \"\n",
        "                f\"Recall: {f'{train_recall:.4f}'       if train_recall    is not None else 'N/A'}, \"\n",
        "                f\"F1: {f'{train_f1:.4f}'               if train_f1        is not None else 'N/A'} | \"\n",
        "                f\"Val Loss: {val_loss:.4f}, \"\n",
        "                f\"Acc: {f'{val_acc:.4f}'               if val_acc         is not None else 'N/A'}, \"\n",
        "                f\"Precision: {f'{val_precision:.4f}'   if val_precision   is not None else 'N/A'}, \"\n",
        "                f\"Recall: {f'{val_recall:.4f}'         if val_recall      is not None else 'N/A'}, \"\n",
        "                f\"F1: {f'{val_f1:.4f}'                 if val_f1          is not None else 'N/A'}\"\n",
        "            )\n",
        "\n",
        "        return (\n",
        "            self.train_losses,\n",
        "            self.val_losses,\n",
        "            self.train_accs,\n",
        "            self.val_accs,\n",
        "            self.train_precisions,\n",
        "            self.val_precisions,\n",
        "            self.train_recalls,\n",
        "            self.val_recalls,\n",
        "            self.train_f1s,\n",
        "            self.val_f1s,\n",
        "        )\n",
        "\n",
        "    def __train_part(self):\n",
        "        # print(f\"[DEBUG] jump into __train_part\")\n",
        "        self.model.train()\n",
        "        # print(f\"[DEBUG] {self.model.training}\")\n",
        "        total_loss = 0.0\n",
        "        all_labels = []\n",
        "        all_preds = []\n",
        "        cc=1\n",
        "        for batch in self.train_loader:\n",
        "            print(f\"[DEBUG] batch/epoch: {cc}/{self.epc}\")\n",
        "            cc+=1\n",
        "            if not self.is_MLM:\n",
        "                inputs, labels = batch\n",
        "                # print(f\"[DEBUG] {inputs}\")\n",
        "                # print(f\"[DEBUG] {labels}\")\n",
        "                labels = labels.to(self.device)\n",
        "            else:\n",
        "                inputs = batch\n",
        "                labels = inputs[\"input_ids\"].to(self.device)\n",
        "\n",
        "            input_ids = inputs[\"input_ids\"].to(self.device)\n",
        "            attention_mask = inputs[\"attention_mask\"].to(self.device)\n",
        "\n",
        "            # print(f\"[DEBUG] {input_ids.shape}\")\n",
        "            # print(f\"[DEBUG] {attention_mask.shape}\")\n",
        "            # 拓展： 混合精度前向传播\n",
        "            with torch.amp.autocast(device_type=self.device.type):\n",
        "                if not self.is_MLM:\n",
        "                    outputs = self.model(input_ids=input_ids,attention_mask=attention_mask)\n",
        "                    # print(f\"[DEBUG] {outputs}\")\n",
        "                    loss = self.loss_func(outputs.logits, labels)\n",
        "                else:\n",
        "                    outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "                    loss = outputs.loss # MLM内含loss\n",
        "\n",
        "            # print(f\"[DEBUG] {loss.item()}\")\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            # loss.backward()\n",
        "            self.scaler.scale(loss).backward()  # 反向传播前对loss乘一个缩放因子，避免梯度过小导致的下溢\n",
        "            self.scaler.unscale_(self.optimizer)  # 反缩放，梯度裁剪通常是基于原始梯度值进行的\n",
        "            # 梯度裁剪 <-- 防止爆炸、稳定训练、加速收敛\n",
        "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
        "            # self.optimizer.step()\n",
        "            self.scaler.step(self.optimizer)\n",
        "            self.scaler.update()  # 更新缩放因子，为下次迭代做准备\n",
        "            self.scheduler.step()\n",
        "\n",
        "            if self.is_MLM:\n",
        "                self.mlm_loss_train.append(loss.item())\n",
        "            total_loss += loss.item()\n",
        "            if not self.is_MLM:\n",
        "                tmp = torch.softmax(outputs.logits, dim=1)\n",
        "                preds = torch.argmax(tmp, dim=1).cpu().numpy()\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "                all_preds.extend(preds)\n",
        "\n",
        "        train_loss = total_loss / len(self.train_loader)\n",
        "\n",
        "        if not self.is_MLM:\n",
        "            train_acc = accuracy_score(all_labels, all_preds)\n",
        "            train_precision = precision_score(all_labels, all_preds, average=\"weighted\")\n",
        "            train_recall = recall_score(all_labels, all_preds, average=\"weighted\")\n",
        "            train_f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n",
        "\n",
        "            # 保存记录\n",
        "            self.train_losses.append(train_loss)\n",
        "            self.train_accs.append(train_acc)\n",
        "            self.train_precisions.append(train_precision)\n",
        "            self.train_recalls.append(train_recall)\n",
        "            self.train_f1s.append(train_f1)\n",
        "            return train_loss, train_acc, train_precision, train_recall, train_f1\n",
        "        else:\n",
        "            return train_loss, None, None, None, None\n",
        "\n",
        "    def _valid_part(self):\n",
        "        self.model.eval()\n",
        "        total_loss = 0.0\n",
        "        all_labels = []\n",
        "        all_preds = []\n",
        "        cc=1\n",
        "        with torch.no_grad():\n",
        "            for batch in self.val_loader:\n",
        "                print(f\"[DEBUG] batch/epoch: {cc}/{self.epc}\")\n",
        "                cc+=1\n",
        "                if not self.is_MLM:\n",
        "                    inputs, labels = batch\n",
        "                    labels = labels.to(self.device)\n",
        "                else:\n",
        "                    inputs = batch\n",
        "                    labels = inputs[\"input_ids\"].to(self.device)\n",
        "\n",
        "                input_ids = inputs[\"input_ids\"].to(self.device)\n",
        "                attention_mask = inputs[\"attention_mask\"].to(self.device)\n",
        "\n",
        "                # 拓展： 混合精度前向传播\n",
        "                with torch.amp.autocast(device_type=self.device.type):\n",
        "                    if not self.is_MLM:\n",
        "                        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                        loss = self.loss_func(outputs.logits, labels)\n",
        "                    else:\n",
        "                        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "                        loss = outputs.loss\n",
        "\n",
        "                if self.is_MLM:\n",
        "                    self.mlm_loss_valid.append(loss.item())\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                if not self.is_MLM:\n",
        "                    tmp = torch.softmax(outputs.logits, dim=1)\n",
        "                    preds = torch.argmax(tmp, dim=1).cpu().numpy()\n",
        "                    all_labels.extend(labels.cpu().numpy())\n",
        "                    all_preds.extend(preds)\n",
        "\n",
        "        val_loss = total_loss / len(self.val_loader)\n",
        "\n",
        "        if not self.is_MLM:\n",
        "            val_acc = accuracy_score(all_labels, all_preds)\n",
        "            val_precision = precision_score(all_labels, all_preds, average=\"weighted\")\n",
        "            val_recall = recall_score(all_labels, all_preds, average=\"weighted\")\n",
        "            val_f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n",
        "\n",
        "            self.val_losses.append(val_loss)\n",
        "            self.val_accs.append(val_acc)\n",
        "            self.val_precisions.append(val_precision)\n",
        "            self.val_recalls.append(val_recall)\n",
        "            self.val_f1s.append(val_f1)\n",
        "\n",
        "            return val_loss, val_acc, val_precision, val_recall, val_f1\n",
        "        else:\n",
        "            return val_loss, None, None, None, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "e58nHX3Tnac1"
      },
      "outputs": [],
      "source": [
        "class ModelEvaluator:\n",
        "    def __init__(\n",
        "        self,\n",
        "        test_loader=None,\n",
        "        compare_lists=None,\n",
        "    ):\n",
        "        self.test_loader = test_loader\n",
        "        self.compare_lists = compare_lists\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.fpr= None\n",
        "        self.tpr= None\n",
        "        self.roc_auc= None\n",
        "\n",
        "    def evaluate_model(self, model, analyse=True):\n",
        "        '''\n",
        "        当处于分析模式时，不绘制混淆矩阵，直接返回评估指标\n",
        "        特别注意：本方法要求测试集带有标签\n",
        "        '''\n",
        "        model.to(self.device)\n",
        "        model.eval()\n",
        "\n",
        "        all_labels = []\n",
        "        all_preds = []\n",
        "        cc=0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in self.test_loader:\n",
        "                print(f\"[DEBUG] Testing batch:{cc}\")\n",
        "                cc+=1\n",
        "                inputs = {key: val.to(self.device) for key, val in inputs.items()}\n",
        "                labels = labels.to(self.device)\n",
        "                outputs= model(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])\n",
        "                tmp = torch.softmax(outputs.logits, dim=1)\n",
        "                preds = torch.argmax(tmp, dim=1).tolist()\n",
        "\n",
        "                all_labels.extend(labels.tolist())\n",
        "                all_preds.extend(preds)\n",
        "\n",
        "        # 计算评估指标\n",
        "        test_acc = accuracy_score(all_labels, all_preds)\n",
        "        test_precision = precision_score(all_labels, all_preds)\n",
        "        test_recall = recall_score(all_labels, all_preds)\n",
        "        test_f1 = f1_score(all_labels, all_preds)\n",
        "        self.fpr, self.tpr, _ = roc_curve(all_labels, all_preds)\n",
        "        self.roc_auc = auc(self.fpr, self.tpr)\n",
        "\n",
        "        print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "        print(f\"Test Precision: {test_precision:.4f}\")\n",
        "        print(f\"Test Recall: {test_recall:.4f}\")\n",
        "        print(f\"Test F1 Score: {test_f1:.4f}\")\n",
        "        if analyse:\n",
        "            return test_acc, test_precision, test_recall, test_f1\n",
        "\n",
        "        # 绘制混淆矩阵\n",
        "        cm = confusion_matrix(all_labels, all_preds, labels=[i for i in range(NUM_LABELS)])\n",
        "        disp = ConfusionMatrixDisplay(\n",
        "            confusion_matrix=cm, display_labels=[classes[i] for i in range(NUM_LABELS)]\n",
        "        )\n",
        "        disp.plot(cmap=plt.cm.Blues)\n",
        "        plt.title(\"Confusion Matrix\")\n",
        "        plt.show()\n",
        "\n",
        "    def detect(self, model):\n",
        "        \"\"\"\n",
        "        评估无标签测试集\n",
        "        \"\"\"\n",
        "        model.to(self.device)\n",
        "        model.eval()\n",
        "\n",
        "        all_preds = []\n",
        "        all_confidences = []\n",
        "        cc = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs in self.test_loader:\n",
        "                print(f\"[DEBUG] Testing batch:{cc}\")\n",
        "                cc += 1\n",
        "                inputs = {key: val.to(self.device) for key, val in inputs.items()}\n",
        "                outputs = model(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])\n",
        "                probs = torch.softmax(outputs.logits, dim=1)\n",
        "                preds = torch.argmax(probs, dim=1).tolist()\n",
        "                confidences = torch.max(probs, dim=1).values.tolist()\n",
        "\n",
        "                all_preds.extend(preds)\n",
        "                all_confidences.extend(confidences)\n",
        "\n",
        "        print(f\"Predicted Labels: {all_preds}\")\n",
        "        print(f\"Confidences: {all_confidences}\")\n",
        "        return all_preds, all_confidences\n",
        "\n",
        "    def collect_errors(self, model, tokenizer):\n",
        "        model.to(self.device)\n",
        "        model.eval()\n",
        "\n",
        "        errors = []  # 存储错误分类的样本\n",
        "        cc=1\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in self.test_loader:\n",
        "                print(f\"[DEBUG] Testing batch:{cc}\")\n",
        "                cc+=1\n",
        "                inputs = {key: val.to(self.device) for key, val in inputs.items()}\n",
        "                labels = labels.to(self.device)\n",
        "\n",
        "                # 模型预测\n",
        "                outputs = model(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])\n",
        "                probs = torch.softmax(outputs, dim=1)\n",
        "                preds = torch.argmax(probs, dim=1)\n",
        "\n",
        "                # 收集错误分类的样本\n",
        "                for i in range(len(labels)):\n",
        "                    if preds[i] != labels[i]:\n",
        "                        text = tokenizer.decode(inputs[\"input_ids\"][i], skip_special_tokens=True)\n",
        "                        errors.append({\n",
        "                            \"text\": text,\n",
        "                            \"label\": labels[i].item(),\n",
        "                            \"pred\": preds[i].item()\n",
        "                        })\n",
        "\n",
        "        return errors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoPM0B8Vnac1"
      },
      "source": [
        "### 模型结构\n",
        "\n",
        "直接将 `bert-base-uncased` 作为基础编码器，接上分类层（全连接层+softmax/sigmoid激活）\n",
        "\n",
        "这里只返回`logits`，具体\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "BafzyRExnac1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bert_out: 768\n"
          ]
        }
      ],
      "source": [
        "# 本部分为bert输出维度展示，可不用运行\n",
        "bert_out = AutoModel.from_pretrained(MODEL_PATH).config.hidden_size\n",
        "print(f\"bert_out: {bert_out}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "V2CJcccvnac1"
      },
      "outputs": [],
      "source": [
        "class BertClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BertClassifier, self).__init__()\n",
        "        model_path = MODEL_PATH\n",
        "        self.deberta = AutoModel.from_pretrained(model_path)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.6)\n",
        "        self.classifier = nn.Linear(\n",
        "            self.deberta.config.hidden_size, NUM_LABELS\n",
        "        )  # 分类层\n",
        "        # self.activation = nn.Sigmoid() # 二分类\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        # BERT 编码器\n",
        "        outputs = self.deberta(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        # 基于 [CLS] token 的隐藏状态，经过一个额外的全连接层和 tanh 激活函数后的结果\n",
        "        cls_output = outputs.pooler_output\n",
        "\n",
        "        # Dropout + 分类层\n",
        "        # cls_output = self.dropout(cls_output)\n",
        "        logits = self.classifier(cls_output)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "iDLAYyPOnac1"
      },
      "outputs": [],
      "source": [
        "def compare_eval(initial_metrics, final_metrics):\n",
        "    # 对比前后的性能变化\n",
        "    metrics = [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"]\n",
        "    initial_values = [initial_metrics[0], initial_metrics[1], initial_metrics[2], initial_metrics[3]]\n",
        "    final_values = [final_metrics[0], final_metrics[1], final_metrics[2], final_metrics[3]]\n",
        "\n",
        "    x = range(len(metrics))\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.bar(x, initial_values, width=0.4, label=\"Before Fine-tuning\", align=\"center\")\n",
        "    plt.bar([i + 0.4 for i in x], final_values, width=0.4, label=\"After Fine-tuning\", align=\"center\")\n",
        "    plt.xticks([i + 0.2 for i in x], metrics)\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.title(\"Performance Comparison Before and After Fine-tuning\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def train_show(trainer):\n",
        "    plt.figure(figsize=(15, 10))\n",
        "\n",
        "    # 准确率\n",
        "    plt.subplot(2, 3, 1)\n",
        "    plt.plot(trainer.train_accs, label=\"Train Accuracy\")\n",
        "    plt.plot(trainer.val_accs, label=\"Validation Accuracy\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title(\"Training and Validation Accuracy\")\n",
        "    plt.legend()\n",
        "\n",
        "    # 精确率\n",
        "    plt.subplot(2, 3, 2)\n",
        "    plt.plot(trainer.train_precisions, label=\"Train Precision\")\n",
        "    plt.plot(trainer.val_precisions, label=\"Validation Precision\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Precision\")\n",
        "    plt.title(\"Training and Validation Precision\")\n",
        "    plt.legend()\n",
        "\n",
        "    # 损失\n",
        "    plt.subplot(2, 3, 3)\n",
        "    plt.plot(trainer.train_losses, label=\"Train Loss\")\n",
        "    plt.plot(trainer.val_losses, label=\"Validation Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Training and Validation Loss\")\n",
        "    plt.legend()\n",
        "\n",
        "    # 召回率\n",
        "    plt.subplot(2, 3, 4)\n",
        "    plt.plot(trainer.train_recalls, label=\"Train Recall\")\n",
        "    plt.plot(trainer.val_recalls, label=\"Validation Recall\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Recall\")\n",
        "    plt.title(\"Training and Validation Recall\")\n",
        "    plt.legend()\n",
        "\n",
        "    # F1\n",
        "    plt.subplot(2, 3, 5)\n",
        "    plt.plot(trainer.train_f1s, label=\"Train F1\")\n",
        "    plt.plot(trainer.val_f1s, label=\"Validation F1\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"F1 Score\")\n",
        "    plt.title(\"Training and Validation F1 Score\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oAtM1THnac2"
      },
      "source": [
        "##### 微调"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "wEZQXoIynac2"
      },
      "outputs": [],
      "source": [
        "def layerwise_lr_decay(model, lr=5e-5, decay=0.8):\n",
        "    # 分类头参数（学习率较高）\n",
        "    classifier_params = list(model.classifier.parameters())\n",
        "\n",
        "    # DeBERTa 本体参数（学习率较低）\n",
        "    bert_params = []\n",
        "    bert_lr = lr * 0.5\n",
        "    for i, layer in enumerate(model.deberta.encoder.layer[::-1]):  # 从最后一层开始\n",
        "        bert_params.append({\"params\": layer.parameters(), \"lr\": bert_lr})\n",
        "        bert_lr *= decay  # 每层学习率衰减\n",
        "\n",
        "    # 分类头学习率较高，放在前面确保优化器优先处理\n",
        "    return [{\"params\": classifier_params, \"lr\": lr}] + bert_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "初始化分词器与数据加载器"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "D:\\python\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "avg train text: 433.36\n",
            "avg test text: 460.15\n",
            "                                                text  label\n",
            "0   S. cities. Here's more about Seattle's snowfa...      1\n",
            "1   This paper delves into the interpretability a...      1\n",
            "2   You could sell this toy to all your friends a...      1\n",
            "3   My time to shine . The term \" Rockefeller Rep...      0\n",
            "4   This case raised several ethical and legal qu...      1\n",
            "                                                text\n",
            "0  Employers, colleges, community positions these...\n",
            "1  The USChina trade war may begin to affect soft...\n",
            "2  Proponents of this view argue that because ext...\n",
            "3  Imagine you're at a party, and there are 23 pe...\n",
            "4  Have you ever heard of the locked in syndrome?...\n",
            "label\n",
            "1    0.532393\n",
            "0    0.467607\n",
            "Name: proportion, dtype: float64\n",
            "avg train text(final): 415.88\n",
            "avg test text(final): 449.99\n",
            "训练集长度: 22400; 验证集长度: 5600; 测试集长度: 2800\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
        "train_loader, valid_loader, test_loader = load_data(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "D0F7WkcDnac2"
      },
      "outputs": [],
      "source": [
        "# 初始化模型和数据\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_PATH, num_labels=NUM_LABELS\n",
        ")\n",
        "model.to(device)\n",
        "\n",
        "params = layerwise_lr_decay(model)\n",
        "optimizer = AdamW(params, weight_decay=0.01)\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer, num_warmup_steps=2, num_training_steps=len(train_loader) * EPOCHS\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcUqJd0p-F8b"
      },
      "outputs": [],
      "source": [
        "# 初始化训练器\n",
        "trainer = ModelTrainer(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=valid_loader,\n",
        "    epochs=EPOCHS,\n",
        "    lr=5e-5,\n",
        ")\n",
        "trainer.optimizer = optimizer  # 覆盖默认优化器 <-- 引入分层学习率\n",
        "trainer.scheduler = scheduler\n",
        "trainer.save_name = MODEL_PRE_NAME\n",
        "\n",
        "evaluator = ModelEvaluator(test_loader=valid_loader)\n",
        "print(\"微调前的性能：\")\n",
        "initial_metrics = evaluator.evaluate_model(model=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2WYxiDanac2"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    import time\n",
        "    torch.cuda.empty_cache()\n",
        "    start_time = time.time()\n",
        "    torch.cuda.reset_peak_memory_stats()\n",
        "    initial_memory = torch.cuda.memory_allocated()\n",
        "\n",
        "# 开始训练\n",
        "trainer.train()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    end_time = time.time()\n",
        "    peak_memory = torch.cuda.max_memory_allocated()\n",
        "    elapsed_time = end_time - start_time\n",
        "    memory_used = peak_memory - initial_memory\n",
        "    print(f\"Elapsed Time: {elapsed_time:.2f} seconds\")\n",
        "    print(f\"Memory Used: {memory_used / (1024 ** 2):.2f} MB\\n\")\n",
        "\n",
        "train_show(trainer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uST4F36I-N4V"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "# 测试模型效果\n",
        "print(\"微调后的性能：\")\n",
        "final_metrics = evaluator.evaluate_model(model=model)\n",
        "\n",
        "# 对比微调前后性能变化\n",
        "compare_eval(initial_metrics, final_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 评估测试集\n",
        "evaluatorr = ModelEvaluator(test_loader=test_loader)\n",
        "predicted_labels, confidences = evaluatorr.detect(model=model)\n",
        "\n",
        "# 将预测结果逐行写入 txt 文件\n",
        "output_file = \"./result/submit.txt\"\n",
        "with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
        "    for label in predicted_labels:\n",
        "        file.write(f\"{label}\\n\")\n",
        "\n",
        "print(f\"预测结果已写入文件: {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(TEST_PATH, 'r', encoding='utf-8') as f:\n",
        "    test_data = [json.loads(line) for line in f]\n",
        "assert len(test_data) == len(confidences), \"测试数据与置信度列表长度不一致！\"\n",
        "\n",
        "# 统计置信度阶梯分布\n",
        "total = len(confidences)\n",
        "greater_95 = sum(1 for c in confidences if c > 0.95)\n",
        "greater_90 = sum(1 for c in confidences if c > 0.90)\n",
        "greater_85 = sum(1 for c in confidences if c > 0.85)\n",
        "greater_75 = sum(1 for c in confidences if c > 0.75)\n",
        "others = total - greater_75\n",
        "\n",
        "# 打印统计信息\n",
        "print(\"置信度统计信息：\")\n",
        "print(f\"大于 95: {greater_95} ({greater_95 / total:.2%})\")\n",
        "print(f\"大于 90: {greater_90} ({greater_90 / total:.2%})\")\n",
        "print(f\"大于 85: {greater_85} ({greater_85 / total:.2%})\")\n",
        "print(f\"大于 75: {greater_75} ({greater_75 / total:.2%})\")\n",
        "print(f\"其它: {others} ({others / total:.2%})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CONF_CHOOSE = 0.95\n",
        "SUBMIT_PATH = \"./result/submit.txt\"  # submit.txt 文件路径\n",
        "\n",
        "# 从 submit.txt 中读取标签\n",
        "with open(SUBMIT_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "    predicted_labels = [int(line.strip()) for line in f]\n",
        "\n",
        "# 确保预测标签数量与测试数据一致\n",
        "assert len(predicted_labels) == len(test_data), \"预测标签数量与测试数据数量不一致！\"\n",
        "\n",
        "# 筛选置信度大于 CONF_CHOOSE 的条目，并添加标签\n",
        "filtered_data = []\n",
        "for i, (data, confidence) in enumerate(zip(test_data, confidences)):\n",
        "    if confidence > CONF_CHOOSE:\n",
        "        data_with_label = data.copy()  # 复制原始数据\n",
        "        data_with_label[\"label\"] = predicted_labels[i]  # 添加标签\n",
        "        filtered_data.append(data_with_label)\n",
        "\n",
        "# 保存到 pseudo.jsonl 文件\n",
        "with open(PSEUDO_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "    for entry in filtered_data:\n",
        "        f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "print(\n",
        "    f\"已保存置信度大于 {CONF_CHOOSE} 的条目到 {PSEUDO_PATH}，共 {len(filtered_data)} 条。\"\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "YLVFHsYhnac1",
        "TKdxK-eAnac2"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
