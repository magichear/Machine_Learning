{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd0b084b",
   "metadata": {},
   "source": [
    "此处为附带的训练脚本，其中包含了使用附件各库的逻辑及完整训练与测试逻辑，最后一部分的单元格中包含了可用于提交的`agent`代码\n",
    "\n",
    "需要注意的是： 由于我同时在本机与`vlab`平台上进行多种参数的测试，本脚本中并没有包含报告中的所有测试结果，但保证基本逻辑的正确性\n",
    "\n",
    "并且需要特别注意的是：`agent_minmax`系列已经大幅度修改，仅保留了最终修缮结果（即`agent_minmax_4`），因此其它`minmax`版本后方带有的数字表示的是最终算法允许的深度情况，而非版本信息\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4adfea54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "from agent_minmax import agent_minmax\n",
    "from stable_baselines3 import PPO, DQN\n",
    "from ConnectXTrainer import ConnectXTrainer\n",
    "from kaggle_environments import make, evaluate\n",
    "from agent_minmax_2 import agent_minmax_2\n",
    "from agent_minmax_3 import agent_minmax_3\n",
    "from agent_minmax_4 import agent_minmax_4\n",
    "from agent_random import agent_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c053a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    try:\n",
    "        model = PPO.load(model_path)\n",
    "    except:\n",
    "        model = DQN.load(model_path)\n",
    "    print(f\"模型已从 {model_path} 加载\")\n",
    "    return model\n",
    "\n",
    "# 跑 100 次\n",
    "def test_win_rate(agent1, agent2=agent_minmax, num_episodes=100):\n",
    "    rewards = evaluate(\n",
    "        \"connectx\", [agent1, agent2], configuration={}, num_episodes=num_episodes\n",
    "    )\n",
    "    valid_rewards = [r for r in rewards if r[0] is not None and r[1] is not None]\n",
    "\n",
    "    if not valid_rewards:\n",
    "        print(\"No valid games were played.\")\n",
    "        return 0.0\n",
    "\n",
    "    # 计算 agent1 的胜率\n",
    "    win_rate = sum(1 for r in valid_rewards if r[0] > r[1]) / len(valid_rewards)\n",
    "    return win_rate\n",
    "\n",
    "\n",
    "def rename_models(prefix=\"offensive\", models_path_raw=None):\n",
    "    for file_path in models_path_raw:\n",
    "        dir_name, base_name = os.path.split(file_path)\n",
    "        split_index = base_name.find(\"_\")\n",
    "        if split_index != -1:\n",
    "            new_name = f\"{prefix}{base_name[split_index:]}\"\n",
    "        else:\n",
    "            new_name = f\"{prefix}_{base_name}\"\n",
    "        new_path = os.path.join(dir_name, new_name)\n",
    "        shutil.move(file_path, new_path)\n",
    "        print(f\"文件已重命名: {file_path} -> {new_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc2e0408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Logging to ./connectx_tensorboard/PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 5.35     |\n",
      "|    ep_rew_mean     | -8.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 362      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 6.35        |\n",
      "|    ep_rew_mean          | -7.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 349         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027736673 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | 0.005313456 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0277     |\n",
      "|    value_loss           | 32.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 7.26        |\n",
      "|    ep_rew_mean          | -6.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 331         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014104556 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.036580205 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.028      |\n",
      "|    value_loss           | 31.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 6.98        |\n",
      "|    ep_rew_mean          | -4.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 321         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011168376 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.84       |\n",
      "|    explained_variance   | 0.03550327  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0268     |\n",
      "|    value_loss           | 39.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 7.57        |\n",
      "|    ep_rew_mean          | -2.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 327         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012895305 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.78       |\n",
      "|    explained_variance   | 0.08713889  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.4        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0336     |\n",
      "|    value_loss           | 50.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 7.72        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 331         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015690308 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.71       |\n",
      "|    explained_variance   | 0.12056172  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.9        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0372     |\n",
      "|    value_loss           | 55          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 7.78        |\n",
      "|    ep_rew_mean          | 3           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 335         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015941575 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 0.087833166 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28.7        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0365     |\n",
      "|    value_loss           | 62.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 7.63        |\n",
      "|    ep_rew_mean          | 5.4         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 336         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015893925 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.06545687  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.8        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0331     |\n",
      "|    value_loss           | 56          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 7.63        |\n",
      "|    ep_rew_mean          | 6.4         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 337         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016951017 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0.102083266 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 24          |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0369     |\n",
      "|    value_loss           | 49          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 7.15        |\n",
      "|    ep_rew_mean          | 8.6         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 338         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012860622 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.08457148  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0265     |\n",
      "|    value_loss           | 40          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 6.94         |\n",
      "|    ep_rew_mean          | 9            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 336          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 66           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.017399551  |\n",
      "|    clip_fraction        | 0.177        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | -0.022092938 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.86         |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.0256      |\n",
      "|    value_loss           | 21.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 7.02         |\n",
      "|    ep_rew_mean          | 9            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 331          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 74           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.018015116  |\n",
      "|    clip_fraction        | 0.218        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.16        |\n",
      "|    explained_variance   | -0.017053485 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.72         |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.0212      |\n",
      "|    value_loss           | 8.77         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 6.83        |\n",
      "|    ep_rew_mean          | 9.6         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 327         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 81          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013922394 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.06555033  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.46        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0224     |\n",
      "|    value_loss           | 10.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 6.37        |\n",
      "|    ep_rew_mean          | 9.4         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 325         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 88          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016231844 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.994      |\n",
      "|    explained_variance   | 0.042235196 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.61        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0251     |\n",
      "|    value_loss           | 14.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.87        |\n",
      "|    ep_rew_mean          | 10          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 324         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017484773 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.869      |\n",
      "|    explained_variance   | 0.1609006   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.5         |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0227     |\n",
      "|    value_loss           | 7.6         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.7         |\n",
      "|    ep_rew_mean          | 9.6         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 322         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02190986  |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.71       |\n",
      "|    explained_variance   | -0.09481919 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.01       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    value_loss           | 1.85        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.26        |\n",
      "|    ep_rew_mean          | 10          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 108         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.04075291  |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.598      |\n",
      "|    explained_variance   | 0.009501159 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0441     |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0249     |\n",
      "|    value_loss           | 3.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.82        |\n",
      "|    ep_rew_mean          | 9.4         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 116         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025782831 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.476      |\n",
      "|    explained_variance   | 0.03308183  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0188     |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0251     |\n",
      "|    value_loss           | 1.9         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.63         |\n",
      "|    ep_rew_mean          | 9.8          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 312          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 124          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073252833 |\n",
      "|    clip_fraction        | 0.148        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.395       |\n",
      "|    explained_variance   | 0.0020192266 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00532      |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.0162      |\n",
      "|    value_loss           | 5.07         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.49        |\n",
      "|    ep_rew_mean          | 10          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 132         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01773376  |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.319      |\n",
      "|    explained_variance   | 0.006119132 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.07        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    value_loss           | 4.5         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.23        |\n",
      "|    ep_rew_mean          | 10          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 305         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 140         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.083596915 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.271      |\n",
      "|    explained_variance   | 0.0168131   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.16        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0594     |\n",
      "|    value_loss           | 0.659       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.27         |\n",
      "|    ep_rew_mean          | 10           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 301          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 149          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035551956 |\n",
      "|    clip_fraction        | 0.0508       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.167       |\n",
      "|    explained_variance   | 0.005479753  |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0203      |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.0138      |\n",
      "|    value_loss           | 1.96         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.03        |\n",
      "|    ep_rew_mean          | 10          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 297         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 158         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046921417 |\n",
      "|    clip_fraction        | 0.0589      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.11       |\n",
      "|    explained_variance   | 0.009151459 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0243     |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0217     |\n",
      "|    value_loss           | 1.96        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.07         |\n",
      "|    ep_rew_mean          | 9.6          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 293          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 167          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039671855 |\n",
      "|    clip_fraction        | 0.0124       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0494      |\n",
      "|    explained_variance   | 0.0054136515 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00459      |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00923     |\n",
      "|    value_loss           | 1.96         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.02         |\n",
      "|    ep_rew_mean          | 9.4          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 290          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 176          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016957644 |\n",
      "|    clip_fraction        | 0.0119       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0351      |\n",
      "|    explained_variance   | 0.024294317  |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0309      |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.0128      |\n",
      "|    value_loss           | 1.29         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4            |\n",
      "|    ep_rew_mean          | 9.6          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 287          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 185          |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016305657 |\n",
      "|    clip_fraction        | 0.0082       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0269      |\n",
      "|    explained_variance   | 0.013092697  |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.49         |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00717     |\n",
      "|    value_loss           | 3.21         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.02          |\n",
      "|    ep_rew_mean          | 10            |\n",
      "| time/                   |               |\n",
      "|    fps                  | 284           |\n",
      "|    iterations           | 27            |\n",
      "|    time_elapsed         | 194           |\n",
      "|    total_timesteps      | 55296         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027918178 |\n",
      "|    clip_fraction        | 0.00234       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0152       |\n",
      "|    explained_variance   | 0.005201757   |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.000417      |\n",
      "|    n_updates            | 260           |\n",
      "|    policy_gradient_loss | -0.00325      |\n",
      "|    value_loss           | 1.97          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.39        |\n",
      "|    ep_rew_mean          | 10          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 202         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044228997 |\n",
      "|    clip_fraction        | 0.0854      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0726     |\n",
      "|    explained_variance   | 0.05300206  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0152     |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 0.631       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.07       |\n",
      "|    ep_rew_mean          | 10         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 281        |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 210        |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22975409 |\n",
      "|    clip_fraction        | 0.247      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0531    |\n",
      "|    explained_variance   | 0.69851017 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0814    |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | -0.00876   |\n",
      "|    value_loss           | 0.0018     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=10.00 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 10           |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 60000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047289957 |\n",
      "|    clip_fraction        | 0.00894      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0263      |\n",
      "|    explained_variance   | 0.016459525  |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0102      |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.00802     |\n",
      "|    value_loss           | 0.658        |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 4.01     |\n",
      "|    ep_rew_mean     | 10       |\n",
      "| time/              |          |\n",
      "|    fps             | 279      |\n",
      "|    iterations      | 30       |\n",
      "|    time_elapsed    | 219      |\n",
      "|    total_timesteps | 61440    |\n",
      "---------------------------------\n",
      "模型已保存为: ./connectx_models/ppo_60000_60000.zip\n",
      "Logging to ./connectx_tensorboard/PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 4        |\n",
      "|    ep_rew_mean     | 10       |\n",
      "| time/              |          |\n",
      "|    fps             | 287      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 63488    |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4             |\n",
      "|    ep_rew_mean          | 10            |\n",
      "| time/                   |               |\n",
      "|    fps                  | 266           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 15            |\n",
      "|    total_timesteps      | 65536         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00075252046 |\n",
      "|    clip_fraction        | 0.0022        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00733      |\n",
      "|    explained_variance   | 0.8437815     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.00464      |\n",
      "|    n_updates            | 310           |\n",
      "|    policy_gradient_loss | -0.00359      |\n",
      "|    value_loss           | 0.00119       |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 5.71       |\n",
      "|    ep_rew_mean          | 10         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 22         |\n",
      "|    total_timesteps      | 67584      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 1.7385638  |\n",
      "|    clip_fraction        | 0.304      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.075     |\n",
      "|    explained_variance   | 0.99995685 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0807    |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.0512    |\n",
      "|    value_loss           | 3.97e-07   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 5.15       |\n",
      "|    ep_rew_mean          | 10         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 280        |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 29         |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12404658 |\n",
      "|    clip_fraction        | 0.381      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.269     |\n",
      "|    explained_variance   | 0.45106912 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0715    |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.063     |\n",
      "|    value_loss           | 0.0088     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.87       |\n",
      "|    ep_rew_mean          | 10         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 36         |\n",
      "|    total_timesteps      | 71680      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11319656 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.163     |\n",
      "|    explained_variance   | 0.93335885 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0362    |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.0319    |\n",
      "|    value_loss           | 0.00132    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.79        |\n",
      "|    ep_rew_mean          | 10          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017388858 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.205      |\n",
      "|    explained_variance   | 0.9590752   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0412     |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0414     |\n",
      "|    value_loss           | 0.000771    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.62        |\n",
      "|    ep_rew_mean          | 10          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018077265 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.2        |\n",
      "|    explained_variance   | 0.93020546  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0531     |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0546     |\n",
      "|    value_loss           | 0.00125     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.31        |\n",
      "|    ep_rew_mean          | 10          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 275         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027434342 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.159      |\n",
      "|    explained_variance   | 0.9025732   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0695     |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0651     |\n",
      "|    value_loss           | 0.00163     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.13        |\n",
      "|    ep_rew_mean          | 10          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 67          |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018869758 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0857     |\n",
      "|    explained_variance   | 0.9080334   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0624     |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0516     |\n",
      "|    value_loss           | 0.00139     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 10         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 75         |\n",
      "|    total_timesteps      | 81920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15648654 |\n",
      "|    clip_fraction        | 0.0414     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0129    |\n",
      "|    explained_variance   | 0.92950135 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0474    |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | -0.0403    |\n",
      "|    value_loss           | 0.000993   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4            |\n",
      "|    ep_rew_mean          | 10           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 267          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 84           |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.487837e-05 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00262     |\n",
      "|    explained_variance   | 0.9954193    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.000166    |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.00072     |\n",
      "|    value_loss           | 2.15e-05     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.97       |\n",
      "|    ep_rew_mean          | 10         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 269        |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 91         |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.57361555 |\n",
      "|    clip_fraction        | 0.11       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0626    |\n",
      "|    explained_variance   | 0.99998456 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0938    |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.023     |\n",
      "|    value_loss           | 9.27e-09   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.75        |\n",
      "|    ep_rew_mean          | 10          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033194676 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.194      |\n",
      "|    explained_variance   | 0.904411    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0201     |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    value_loss           | 0.000372    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.68        |\n",
      "|    ep_rew_mean          | 10          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 106         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014303219 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.211      |\n",
      "|    explained_variance   | 0.9232867   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0537     |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0512     |\n",
      "|    value_loss           | 0.00131     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.3         |\n",
      "|    ep_rew_mean          | 10          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 267         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 114         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022421172 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.181      |\n",
      "|    explained_variance   | 0.9007741   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0606     |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.063      |\n",
      "|    value_loss           | 0.00172     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.06       |\n",
      "|    ep_rew_mean          | 10         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 265        |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 123        |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10830284 |\n",
      "|    clip_fraction        | 0.237      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0711    |\n",
      "|    explained_variance   | 0.8962901  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0591    |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.0612    |\n",
      "|    value_loss           | 0.00168    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 10          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 132         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.059525438 |\n",
      "|    clip_fraction        | 0.0197      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0111     |\n",
      "|    explained_variance   | 0.9617031   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0226     |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    value_loss           | 0.000508    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4             |\n",
      "|    ep_rew_mean          | 10            |\n",
      "| time/                   |               |\n",
      "|    fps                  | 262           |\n",
      "|    iterations           | 18            |\n",
      "|    time_elapsed         | 140           |\n",
      "|    total_timesteps      | 98304         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019722385 |\n",
      "|    clip_fraction        | 0.000879      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00277      |\n",
      "|    explained_variance   | 0.9959054     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.000138     |\n",
      "|    n_updates            | 470           |\n",
      "|    policy_gradient_loss | -0.00123      |\n",
      "|    value_loss           | 3.08e-05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4             |\n",
      "|    ep_rew_mean          | 10            |\n",
      "| time/                   |               |\n",
      "|    fps                  | 260           |\n",
      "|    iterations           | 19            |\n",
      "|    time_elapsed         | 149           |\n",
      "|    total_timesteps      | 100352        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.9802322e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00183      |\n",
      "|    explained_variance   | 0.9999559     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.000155     |\n",
      "|    n_updates            | 480           |\n",
      "|    policy_gradient_loss | -9.85e-05     |\n",
      "|    value_loss           | 1.03e-07      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4             |\n",
      "|    ep_rew_mean          | 10            |\n",
      "| time/                   |               |\n",
      "|    fps                  | 257           |\n",
      "|    iterations           | 20            |\n",
      "|    time_elapsed         | 158           |\n",
      "|    total_timesteps      | 102400        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4901161e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00166      |\n",
      "|    explained_variance   | 0.99999994    |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -4.8e-05      |\n",
      "|    n_updates            | 490           |\n",
      "|    policy_gradient_loss | -2.48e-05     |\n",
      "|    value_loss           | 6.38e-12      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4            |\n",
      "|    ep_rew_mean          | 10           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 255          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 168          |\n",
      "|    total_timesteps      | 104448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.135914e-05 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00158     |\n",
      "|    explained_variance   | 0.9989629    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.45e-05     |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.00066     |\n",
      "|    value_loss           | 1.42e-05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4             |\n",
      "|    ep_rew_mean          | 10            |\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 22            |\n",
      "|    time_elapsed         | 177           |\n",
      "|    total_timesteps      | 106496        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00037364662 |\n",
      "|    clip_fraction        | 0.000928      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000944     |\n",
      "|    explained_variance   | 0.99763185    |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -1.32e-06     |\n",
      "|    n_updates            | 510           |\n",
      "|    policy_gradient_loss | -0.00144      |\n",
      "|    value_loss           | 3.22e-05      |\n",
      "-------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 4         |\n",
      "|    ep_rew_mean          | 10        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 252       |\n",
      "|    iterations           | 23        |\n",
      "|    time_elapsed         | 186       |\n",
      "|    total_timesteps      | 108544    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000832 |\n",
      "|    explained_variance   | 0.999932  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -1.75e-05 |\n",
      "|    n_updates            | 520       |\n",
      "|    policy_gradient_loss | -9.52e-06 |\n",
      "|    value_loss           | 8.49e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 10         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 251        |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 195        |\n",
      "|    total_timesteps      | 110592     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0        |\n",
      "|    clip_fraction        | 0          |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.000825  |\n",
      "|    explained_variance   | 0.99999976 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -2.26e-05  |\n",
      "|    n_updates            | 530        |\n",
      "|    policy_gradient_loss | -1.03e-05  |\n",
      "|    value_loss           | 1.58e-10   |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4             |\n",
      "|    ep_rew_mean          | 10            |\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 25            |\n",
      "|    time_elapsed         | 204           |\n",
      "|    total_timesteps      | 112640        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2962846e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00153      |\n",
      "|    explained_variance   | 1.0           |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.00054      |\n",
      "|    n_updates            | 540           |\n",
      "|    policy_gradient_loss | -7.44e-05     |\n",
      "|    value_loss           | 1.82e-13      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4            |\n",
      "|    ep_rew_mean          | 10           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 213          |\n",
      "|    total_timesteps      | 114688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.874302e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00162     |\n",
      "|    explained_variance   | 1.0          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.000664    |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | -0.000514    |\n",
      "|    value_loss           | 0            |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 4         |\n",
      "|    ep_rew_mean          | 10        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 248       |\n",
      "|    iterations           | 27        |\n",
      "|    time_elapsed         | 222       |\n",
      "|    total_timesteps      | 116736    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000785 |\n",
      "|    explained_variance   | 1.0       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -2.15e-05 |\n",
      "|    n_updates            | 560       |\n",
      "|    policy_gradient_loss | -1.08e-05 |\n",
      "|    value_loss           | 0         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 4         |\n",
      "|    ep_rew_mean          | 10        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 247       |\n",
      "|    iterations           | 28        |\n",
      "|    time_elapsed         | 231       |\n",
      "|    total_timesteps      | 118784    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000791 |\n",
      "|    explained_variance   | 1.0       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -2.39e-05 |\n",
      "|    n_updates            | 570       |\n",
      "|    policy_gradient_loss | -8.67e-06 |\n",
      "|    value_loss           | 0         |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=120000, episode_reward=10.00 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 10           |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 120000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.589383e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00184     |\n",
      "|    explained_variance   | 1.0          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.000328    |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -6.8e-05     |\n",
      "|    value_loss           | 0            |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 4        |\n",
      "|    ep_rew_mean     | 10       |\n",
      "| time/              |          |\n",
      "|    fps             | 245      |\n",
      "|    iterations      | 29       |\n",
      "|    time_elapsed    | 241      |\n",
      "|    total_timesteps | 120832   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.01         |\n",
      "|    ep_rew_mean          | 10           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 257          |\n",
      "|    total_timesteps      | 122880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005283129 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00466     |\n",
      "|    explained_variance   | 0.99763596   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0246      |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | 0.000585     |\n",
      "|    value_loss           | 4.03e-05     |\n",
      "------------------------------------------\n",
      "模型已保存为: ./connectx_models/ppo_60000_120000.zip\n",
      "Logging to ./connectx_tensorboard/PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 4        |\n",
      "|    ep_rew_mean     | 10       |\n",
      "| time/              |          |\n",
      "|    fps             | 100      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 20       |\n",
      "|    total_timesteps | 124928   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 10         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 37         |\n",
      "|    total_timesteps      | 126976     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0        |\n",
      "|    clip_fraction        | 0          |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.000539  |\n",
      "|    explained_variance   | 0.99962014 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -4.61e-06  |\n",
      "|    n_updates            | 610        |\n",
      "|    policy_gradient_loss | -2.25e-06  |\n",
      "|    value_loss           | 3.05e-07   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 4         |\n",
      "|    ep_rew_mean          | 10        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 132       |\n",
      "|    iterations           | 3         |\n",
      "|    time_elapsed         | 46        |\n",
      "|    total_timesteps      | 129024    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000519 |\n",
      "|    explained_variance   | 0.9999965 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -1.52e-05 |\n",
      "|    n_updates            | 620       |\n",
      "|    policy_gradient_loss | -9.47e-06 |\n",
      "|    value_loss           | 2.38e-09  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 4         |\n",
      "|    ep_rew_mean          | 10        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 118       |\n",
      "|    iterations           | 4         |\n",
      "|    time_elapsed         | 69        |\n",
      "|    total_timesteps      | 131072    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000502 |\n",
      "|    explained_variance   | 1.0       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -1.22e-05 |\n",
      "|    n_updates            | 630       |\n",
      "|    policy_gradient_loss | -4.88e-06 |\n",
      "|    value_loss           | 4.47e-12  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.03        |\n",
      "|    ep_rew_mean          | 8.4         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 92          |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028526004 |\n",
      "|    clip_fraction        | 0.0161      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0158     |\n",
      "|    explained_variance   | 1.0         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0626     |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.00308    |\n",
      "|    value_loss           | 3.11e-12    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.1          |\n",
      "|    ep_rew_mean          | 9.6          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 114          |\n",
      "|    total_timesteps      | 135168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.05094178   |\n",
      "|    clip_fraction        | 0.143        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.198       |\n",
      "|    explained_variance   | 0.0044850707 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.89         |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.0407      |\n",
      "|    value_loss           | 13.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 10          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 138         |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038305134 |\n",
      "|    clip_fraction        | 0.0971      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0908     |\n",
      "|    explained_variance   | -0.72332776 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0652      |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    value_loss           | 2.99        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.07       |\n",
      "|    ep_rew_mean          | 10         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 101        |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 162        |\n",
      "|    total_timesteps      | 139264     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02994285 |\n",
      "|    clip_fraction        | 0.0375     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0755    |\n",
      "|    explained_variance   | 0.01652801 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0148    |\n",
      "|    n_updates            | 670        |\n",
      "|    policy_gradient_loss | 0.0417     |\n",
      "|    value_loss           | 0.658      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 10         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 99         |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 185        |\n",
      "|    total_timesteps      | 141312     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02149254 |\n",
      "|    clip_fraction        | 0.0262     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0342    |\n",
      "|    explained_variance   | 0.79597193 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00668   |\n",
      "|    n_updates            | 680        |\n",
      "|    policy_gradient_loss | -0.00494   |\n",
      "|    value_loss           | 0.00141    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.01        |\n",
      "|    ep_rew_mean          | 10          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 201         |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000963876 |\n",
      "|    clip_fraction        | 0.00288     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.00972    |\n",
      "|    explained_variance   | 0.7829722   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0235     |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.00386    |\n",
      "|    value_loss           | 0.00179     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.42       |\n",
      "|    ep_rew_mean          | 9.6        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 208        |\n",
      "|    total_timesteps      | 145408     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.1787027  |\n",
      "|    clip_fraction        | 0.392      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.288     |\n",
      "|    explained_variance   | 0.99436855 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00863   |\n",
      "|    n_updates            | 700        |\n",
      "|    policy_gradient_loss | 1.45       |\n",
      "|    value_loss           | 5.98e-05   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.5          |\n",
      "|    ep_rew_mean          | 9.8          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 215          |\n",
      "|    total_timesteps      | 147456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.020019924  |\n",
      "|    clip_fraction        | 0.146        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.211       |\n",
      "|    explained_variance   | 0.0010693669 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.3          |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.00899     |\n",
      "|    value_loss           | 7.65         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.28        |\n",
      "|    ep_rew_mean          | 10          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 223         |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.04499854  |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.168      |\n",
      "|    explained_variance   | 0.008646071 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00544    |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.00832    |\n",
      "|    value_loss           | 2.61        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.07       |\n",
      "|    ep_rew_mean          | 10         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 123        |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 231        |\n",
      "|    total_timesteps      | 151552     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07675432 |\n",
      "|    clip_fraction        | 0.231      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0434    |\n",
      "|    explained_variance   | 0.7915993  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0241    |\n",
      "|    n_updates            | 730        |\n",
      "|    policy_gradient_loss | -0.0275    |\n",
      "|    value_loss           | 0.00145    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 10          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 239         |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053428188 |\n",
      "|    clip_fraction        | 0.0153      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.00567    |\n",
      "|    explained_variance   | 0.95645404  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00432    |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    value_loss           | 0.000449    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.01       |\n",
      "|    ep_rew_mean          | 10         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 132        |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 247        |\n",
      "|    total_timesteps      | 155648     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0        |\n",
      "|    clip_fraction        | 0          |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.00243   |\n",
      "|    explained_variance   | 0.99919546 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -2.88e-05  |\n",
      "|    n_updates            | 750        |\n",
      "|    policy_gradient_loss | -1.41e-05  |\n",
      "|    value_loss           | 1.06e-06   |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4             |\n",
      "|    ep_rew_mean          | 10            |\n",
      "| time/                   |               |\n",
      "|    fps                  | 135           |\n",
      "|    iterations           | 17            |\n",
      "|    time_elapsed         | 256           |\n",
      "|    total_timesteps      | 157696        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1358294e-05 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00172      |\n",
      "|    explained_variance   | 0.9989477     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -1.37e-05     |\n",
      "|    n_updates            | 760           |\n",
      "|    policy_gradient_loss | -0.000647     |\n",
      "|    value_loss           | 1.3e-05       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4             |\n",
      "|    ep_rew_mean          | 10            |\n",
      "| time/                   |               |\n",
      "|    fps                  | 139           |\n",
      "|    iterations           | 18            |\n",
      "|    time_elapsed         | 265           |\n",
      "|    total_timesteps      | 159744        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4901161e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0024       |\n",
      "|    explained_variance   | 0.9999966     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -5.29e-05     |\n",
      "|    n_updates            | 770           |\n",
      "|    policy_gradient_loss | -2.14e-05     |\n",
      "|    value_loss           | 4.28e-09      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4             |\n",
      "|    ep_rew_mean          | 10            |\n",
      "| time/                   |               |\n",
      "|    fps                  | 136           |\n",
      "|    iterations           | 19            |\n",
      "|    time_elapsed         | 284           |\n",
      "|    total_timesteps      | 161792        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.9802322e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00233      |\n",
      "|    explained_variance   | 0.99999994    |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -6.59e-05     |\n",
      "|    n_updates            | 780           |\n",
      "|    policy_gradient_loss | -3.55e-05     |\n",
      "|    value_loss           | 4.24e-11      |\n",
      "-------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 4         |\n",
      "|    ep_rew_mean          | 10        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 133       |\n",
      "|    iterations           | 20        |\n",
      "|    time_elapsed         | 307       |\n",
      "|    total_timesteps      | 163840    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.00157  |\n",
      "|    explained_variance   | 1.0       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.000101 |\n",
      "|    n_updates            | 790       |\n",
      "|    policy_gradient_loss | -5.15e-05 |\n",
      "|    value_loss           | 2.03e-13  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 4        |\n",
      "|    ep_rew_mean          | 10       |\n",
      "| time/                   |          |\n",
      "|    fps                  | 129      |\n",
      "|    iterations           | 21       |\n",
      "|    time_elapsed         | 331      |\n",
      "|    total_timesteps      | 165888   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.00152 |\n",
      "|    explained_variance   | 1.0      |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0        |\n",
      "|    n_updates            | 800      |\n",
      "|    policy_gradient_loss | 0        |\n",
      "|    value_loss           | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 4        |\n",
      "|    ep_rew_mean          | 10       |\n",
      "| time/                   |          |\n",
      "|    fps                  | 126      |\n",
      "|    iterations           | 22       |\n",
      "|    time_elapsed         | 355      |\n",
      "|    total_timesteps      | 167936   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.00152 |\n",
      "|    explained_variance   | 1.0      |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0        |\n",
      "|    n_updates            | 810      |\n",
      "|    policy_gradient_loss | 0        |\n",
      "|    value_loss           | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 4        |\n",
      "|    ep_rew_mean          | 10       |\n",
      "| time/                   |          |\n",
      "|    fps                  | 124      |\n",
      "|    iterations           | 23       |\n",
      "|    time_elapsed         | 379      |\n",
      "|    total_timesteps      | 169984   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.00152 |\n",
      "|    explained_variance   | 1.0      |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0        |\n",
      "|    n_updates            | 820      |\n",
      "|    policy_gradient_loss | 0        |\n",
      "|    value_loss           | 0        |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.03         |\n",
      "|    ep_rew_mean          | 10           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 126          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 388          |\n",
      "|    total_timesteps      | 172032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005930423 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.000924    |\n",
      "|    explained_variance   | 0.9986364    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.35e-07     |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.000673    |\n",
      "|    value_loss           | 1.72e-05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4            |\n",
      "|    ep_rew_mean          | 10           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 127          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 402          |\n",
      "|    total_timesteps      | 174080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019647456 |\n",
      "|    clip_fraction        | 0.00176      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00122     |\n",
      "|    explained_variance   | 0.9921818    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -6.1e-05     |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.00277     |\n",
      "|    value_loss           | 7.96e-05     |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 4         |\n",
      "|    ep_rew_mean          | 10        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 129       |\n",
      "|    iterations           | 26        |\n",
      "|    time_elapsed         | 410       |\n",
      "|    total_timesteps      | 176128    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000368 |\n",
      "|    explained_variance   | 0.9999589 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -2.44e-06 |\n",
      "|    n_updates            | 850       |\n",
      "|    policy_gradient_loss | -1.48e-06 |\n",
      "|    value_loss           | 1.55e-08  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 4         |\n",
      "|    ep_rew_mean          | 10        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 132       |\n",
      "|    iterations           | 27        |\n",
      "|    time_elapsed         | 418       |\n",
      "|    total_timesteps      | 178176    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000363 |\n",
      "|    explained_variance   | 0.9999998 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -1.35e-06 |\n",
      "|    n_updates            | 860       |\n",
      "|    policy_gradient_loss | -5.31e-07 |\n",
      "|    value_loss           | 1.78e-10  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=180000, episode_reward=10.00 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 4         |\n",
      "|    mean_reward          | 10        |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 180000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000378 |\n",
      "|    explained_variance   | 1.0       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -5.34e-06 |\n",
      "|    n_updates            | 870       |\n",
      "|    policy_gradient_loss | -2.51e-06 |\n",
      "|    value_loss           | 5.77e-13  |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 4        |\n",
      "|    ep_rew_mean     | 10       |\n",
      "| time/              |          |\n",
      "|    fps             | 134      |\n",
      "|    iterations      | 28       |\n",
      "|    time_elapsed    | 427      |\n",
      "|    total_timesteps | 180224   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 4         |\n",
      "|    ep_rew_mean          | 10        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 136       |\n",
      "|    iterations           | 29        |\n",
      "|    time_elapsed         | 436       |\n",
      "|    total_timesteps      | 182272    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000377 |\n",
      "|    explained_variance   | 1.0       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -2.7e-06  |\n",
      "|    n_updates            | 880       |\n",
      "|    policy_gradient_loss | -1.53e-06 |\n",
      "|    value_loss           | 4.44e-16  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 4         |\n",
      "|    ep_rew_mean          | 10        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 138       |\n",
      "|    iterations           | 30        |\n",
      "|    time_elapsed         | 444       |\n",
      "|    total_timesteps      | 184320    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000343 |\n",
      "|    explained_variance   | 1.0       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -2.33e-06 |\n",
      "|    n_updates            | 890       |\n",
      "|    policy_gradient_loss | -1.28e-06 |\n",
      "|    value_loss           | 4.44e-16  |\n",
      "---------------------------------------\n",
      "模型已保存为: ./connectx_models/ppo_60000_180000.zip\n",
      "Logging to ./connectx_tensorboard/PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 4        |\n",
      "|    ep_rew_mean     | 10       |\n",
      "| time/              |          |\n",
      "|    fps             | 275      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 186368   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 4         |\n",
      "|    ep_rew_mean          | 10        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 234       |\n",
      "|    iterations           | 2         |\n",
      "|    time_elapsed         | 17        |\n",
      "|    total_timesteps      | 188416    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000302 |\n",
      "|    explained_variance   | 1.0       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -2.21e-06 |\n",
      "|    n_updates            | 910       |\n",
      "|    policy_gradient_loss | -8.05e-07 |\n",
      "|    value_loss           | 4.44e-16  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 4         |\n",
      "|    ep_rew_mean          | 10        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 215       |\n",
      "|    iterations           | 3         |\n",
      "|    time_elapsed         | 28        |\n",
      "|    total_timesteps      | 190464    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.0003   |\n",
      "|    explained_variance   | 1.0       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -2.3e-06  |\n",
      "|    n_updates            | 920       |\n",
      "|    policy_gradient_loss | -1.12e-06 |\n",
      "|    value_loss           | 3.73e-15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 4         |\n",
      "|    ep_rew_mean          | 10        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 221       |\n",
      "|    iterations           | 4         |\n",
      "|    time_elapsed         | 36        |\n",
      "|    total_timesteps      | 192512    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000327 |\n",
      "|    explained_variance   | 1.0       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -5.42e-06 |\n",
      "|    n_updates            | 930       |\n",
      "|    policy_gradient_loss | -1.93e-06 |\n",
      "|    value_loss           | 4.44e-16  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.99       |\n",
      "|    ep_rew_mean          | 10         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 232        |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 44         |\n",
      "|    total_timesteps      | 194560     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22484148 |\n",
      "|    clip_fraction        | 0.0129     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.00603   |\n",
      "|    explained_variance   | 1.0        |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0579    |\n",
      "|    n_updates            | 940        |\n",
      "|    policy_gradient_loss | -0.0028    |\n",
      "|    value_loss           | 4.44e-16   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 4.01      |\n",
      "|    ep_rew_mean          | 10        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 234       |\n",
      "|    iterations           | 6         |\n",
      "|    time_elapsed         | 52        |\n",
      "|    total_timesteps      | 196608    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0479181 |\n",
      "|    clip_fraction        | 0.2       |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.00758  |\n",
      "|    explained_variance   | 0.7632432 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.04     |\n",
      "|    n_updates            | 950       |\n",
      "|    policy_gradient_loss | -0.0358   |\n",
      "|    value_loss           | 0.000341  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 10          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 198656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001379191 |\n",
      "|    clip_fraction        | 0.000488    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.000959   |\n",
      "|    explained_variance   | 0.88345057  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000589   |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.00073    |\n",
      "|    value_loss           | 0.00012     |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4             |\n",
      "|    ep_rew_mean          | 10            |\n",
      "| time/                   |               |\n",
      "|    fps                  | 235           |\n",
      "|    iterations           | 8             |\n",
      "|    time_elapsed         | 69            |\n",
      "|    total_timesteps      | 200704        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8510036e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000649     |\n",
      "|    explained_variance   | 0.99864316    |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -9.59e-05     |\n",
      "|    n_updates            | 970           |\n",
      "|    policy_gradient_loss | -2.01e-05     |\n",
      "|    value_loss           | 7.53e-07      |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 5.38       |\n",
      "|    ep_rew_mean          | 9.8        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 240        |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 76         |\n",
      "|    total_timesteps      | 202752     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 2.921255   |\n",
      "|    clip_fraction        | 0.553      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.133     |\n",
      "|    explained_variance   | 0.99999595 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0816    |\n",
      "|    n_updates            | 980        |\n",
      "|    policy_gradient_loss | -0.0623    |\n",
      "|    value_loss           | 1.73e-09   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.21         |\n",
      "|    ep_rew_mean          | 10           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 244          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 83           |\n",
      "|    total_timesteps      | 204800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.07737346   |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.106       |\n",
      "|    explained_variance   | 0.0027447343 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00601      |\n",
      "|    n_updates            | 990          |\n",
      "|    policy_gradient_loss | -0.0132      |\n",
      "|    value_loss           | 2.99         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.82       |\n",
      "|    ep_rew_mean          | 10         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 246        |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 91         |\n",
      "|    total_timesteps      | 206848     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15946135 |\n",
      "|    clip_fraction        | 0.306      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0959    |\n",
      "|    explained_variance   | 0.5485178  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0439    |\n",
      "|    n_updates            | 1000       |\n",
      "|    policy_gradient_loss | -0.0369    |\n",
      "|    value_loss           | 0.00221    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.78        |\n",
      "|    ep_rew_mean          | 7.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 208896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011090985 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.286      |\n",
      "|    explained_variance   | 0.18738216  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0645     |\n",
      "|    n_updates            | 1010        |\n",
      "|    policy_gradient_loss | -0.0484     |\n",
      "|    value_loss           | 0.00301     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.81         |\n",
      "|    ep_rew_mean          | 8.8          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 106          |\n",
      "|    total_timesteps      | 210944       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011398397  |\n",
      "|    clip_fraction        | 0.221        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.29        |\n",
      "|    explained_variance   | 0.0024596453 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 13.7         |\n",
      "|    n_updates            | 1020         |\n",
      "|    policy_gradient_loss | -0.0348      |\n",
      "|    value_loss           | 33.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.82        |\n",
      "|    ep_rew_mean          | 10          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 113         |\n",
      "|    total_timesteps      | 212992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020513397 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.222      |\n",
      "|    explained_variance   | 0.033968627 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.62        |\n",
      "|    n_updates            | 1030        |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    value_loss           | 16.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.87        |\n",
      "|    ep_rew_mean          | 9.8         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 132         |\n",
      "|    total_timesteps      | 215040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017254915 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.155      |\n",
      "|    explained_variance   | -0.21374214 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00334     |\n",
      "|    n_updates            | 1040        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    value_loss           | 2.01        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.71         |\n",
      "|    ep_rew_mean          | 10           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 212          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 153          |\n",
      "|    total_timesteps      | 217088       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.017024104  |\n",
      "|    clip_fraction        | 0.143        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.154       |\n",
      "|    explained_variance   | 0.0055116415 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0138      |\n",
      "|    n_updates            | 1050         |\n",
      "|    policy_gradient_loss | -0.0102      |\n",
      "|    value_loss           | 0.884        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.59        |\n",
      "|    ep_rew_mean          | 10          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 208         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 167         |\n",
      "|    total_timesteps      | 219136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03690078  |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.153      |\n",
      "|    explained_variance   | 0.029350758 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0637     |\n",
      "|    n_updates            | 1060        |\n",
      "|    policy_gradient_loss | -0.0481     |\n",
      "|    value_loss           | 0.653       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.25       |\n",
      "|    ep_rew_mean          | 10         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 205        |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 179        |\n",
      "|    total_timesteps      | 221184     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04832589 |\n",
      "|    clip_fraction        | 0.217      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.115     |\n",
      "|    explained_variance   | 0.8995265  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0552    |\n",
      "|    n_updates            | 1070       |\n",
      "|    policy_gradient_loss | -0.0478    |\n",
      "|    value_loss           | 0.00145    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.01       |\n",
      "|    ep_rew_mean          | 10         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 191        |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 203        |\n",
      "|    total_timesteps      | 223232     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13591929 |\n",
      "|    clip_fraction        | 0.228      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.018     |\n",
      "|    explained_variance   | 0.8893188  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0404    |\n",
      "|    n_updates            | 1080       |\n",
      "|    policy_gradient_loss | -0.0477    |\n",
      "|    value_loss           | 0.00146    |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4            |\n",
      "|    ep_rew_mean          | 10           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 182          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 224          |\n",
      "|    total_timesteps      | 225280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045963908 |\n",
      "|    clip_fraction        | 0.00239      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00345     |\n",
      "|    explained_variance   | 0.9846102    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00117     |\n",
      "|    n_updates            | 1090         |\n",
      "|    policy_gradient_loss | -0.00353     |\n",
      "|    value_loss           | 8.11e-05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4             |\n",
      "|    ep_rew_mean          | 10            |\n",
      "| time/                   |               |\n",
      "|    fps                  | 184           |\n",
      "|    iterations           | 21            |\n",
      "|    time_elapsed         | 232           |\n",
      "|    total_timesteps      | 227328        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4388061e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00303      |\n",
      "|    explained_variance   | 0.9998731     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.000638     |\n",
      "|    n_updates            | 1100          |\n",
      "|    policy_gradient_loss | -0.000111     |\n",
      "|    value_loss           | 1.2e-07       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.01         |\n",
      "|    ep_rew_mean          | 10           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 187          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 240          |\n",
      "|    total_timesteps      | 229376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017659892 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0116      |\n",
      "|    explained_variance   | 0.9926168    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0237      |\n",
      "|    n_updates            | 1110         |\n",
      "|    policy_gradient_loss | 0.00163      |\n",
      "|    value_loss           | 9.12e-05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 10          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 189         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 248         |\n",
      "|    total_timesteps      | 231424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021896647 |\n",
      "|    clip_fraction        | 0.00811     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.00514    |\n",
      "|    explained_variance   | 0.983455    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0386     |\n",
      "|    n_updates            | 1120        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    value_loss           | 0.00021     |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4             |\n",
      "|    ep_rew_mean          | 10            |\n",
      "| time/                   |               |\n",
      "|    fps                  | 190           |\n",
      "|    iterations           | 24            |\n",
      "|    time_elapsed         | 257           |\n",
      "|    total_timesteps      | 233472        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.9604645e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00114      |\n",
      "|    explained_variance   | 0.9998348     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.00013      |\n",
      "|    n_updates            | 1130          |\n",
      "|    policy_gradient_loss | -8.14e-05     |\n",
      "|    value_loss           | 2.69e-07      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4             |\n",
      "|    ep_rew_mean          | 10            |\n",
      "| time/                   |               |\n",
      "|    fps                  | 192           |\n",
      "|    iterations           | 25            |\n",
      "|    time_elapsed         | 265           |\n",
      "|    total_timesteps      | 235520        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.6019205e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00119      |\n",
      "|    explained_variance   | 0.9999971     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.000249     |\n",
      "|    n_updates            | 1140          |\n",
      "|    policy_gradient_loss | -4.55e-05     |\n",
      "|    value_loss           | 1.47e-09      |\n",
      "-------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 5.84      |\n",
      "|    ep_rew_mean          | 10        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 195       |\n",
      "|    iterations           | 26        |\n",
      "|    time_elapsed         | 272       |\n",
      "|    total_timesteps      | 237568    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.4223328 |\n",
      "|    clip_fraction        | 0.434     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.147    |\n",
      "|    explained_variance   | 1.0       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0879   |\n",
      "|    n_updates            | 1150      |\n",
      "|    policy_gradient_loss | -0.0511   |\n",
      "|    value_loss           | 1.31e-12  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 5.65       |\n",
      "|    ep_rew_mean          | 9.8        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 198        |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 278        |\n",
      "|    total_timesteps      | 239616     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22052085 |\n",
      "|    clip_fraction        | 0.296      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.266     |\n",
      "|    explained_variance   | -1.1010756 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0735    |\n",
      "|    n_updates            | 1160       |\n",
      "|    policy_gradient_loss | -0.0381    |\n",
      "|    value_loss           | 0.00253    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=10.00 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 10           |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 240000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.016638499  |\n",
      "|    clip_fraction        | 0.207        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.341       |\n",
      "|    explained_variance   | 0.0030895472 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.54         |\n",
      "|    n_updates            | 1170         |\n",
      "|    policy_gradient_loss | -0.0141      |\n",
      "|    value_loss           | 3.85         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 5.46     |\n",
      "|    ep_rew_mean     | 10       |\n",
      "| time/              |          |\n",
      "|    fps             | 201      |\n",
      "|    iterations      | 28       |\n",
      "|    time_elapsed    | 285      |\n",
      "|    total_timesteps | 241664   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 5.1        |\n",
      "|    ep_rew_mean          | 10         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 203        |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 292        |\n",
      "|    total_timesteps      | 243712     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0317167  |\n",
      "|    clip_fraction        | 0.302      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.313     |\n",
      "|    explained_variance   | 0.03426504 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0335    |\n",
      "|    n_updates            | 1180       |\n",
      "|    policy_gradient_loss | -0.0288    |\n",
      "|    value_loss           | 1.07       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.58        |\n",
      "|    ep_rew_mean          | 10          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 205         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 299         |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.055143096 |\n",
      "|    clip_fraction        | 0.375       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.219      |\n",
      "|    explained_variance   | 0.84548753  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0692     |\n",
      "|    n_updates            | 1190        |\n",
      "|    policy_gradient_loss | -0.0712     |\n",
      "|    value_loss           | 0.00244     |\n",
      "-----------------------------------------\n",
      "模型已保存为: ./connectx_models/ppo_60000_240000.zip\n",
      "Logging to ./connectx_tensorboard/PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 4.43     |\n",
      "|    ep_rew_mean     | 10       |\n",
      "| time/              |          |\n",
      "|    fps             | 306      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 247808   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.89       |\n",
      "|    ep_rew_mean          | 9.6        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 290        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 14         |\n",
      "|    total_timesteps      | 249856     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06701554 |\n",
      "|    clip_fraction        | 0.324      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.253     |\n",
      "|    explained_variance   | 0.8940164  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0779    |\n",
      "|    n_updates            | 1210       |\n",
      "|    policy_gradient_loss | -0.0615    |\n",
      "|    value_loss           | 0.00174    |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.38         |\n",
      "|    ep_rew_mean          | 10           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 280          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 251904       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.029310312  |\n",
      "|    clip_fraction        | 0.286        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.228       |\n",
      "|    explained_variance   | -0.007429838 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0359      |\n",
      "|    n_updates            | 1220         |\n",
      "|    policy_gradient_loss | -0.0246      |\n",
      "|    value_loss           | 2.59         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.02       |\n",
      "|    ep_rew_mean          | 10         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 222        |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 36         |\n",
      "|    total_timesteps      | 253952     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08002941 |\n",
      "|    clip_fraction        | 0.101      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.102     |\n",
      "|    explained_variance   | 0.5208057  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0586    |\n",
      "|    n_updates            | 1230       |\n",
      "|    policy_gradient_loss | -0.0437    |\n",
      "|    value_loss           | 0.00924    |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4            |\n",
      "|    ep_rew_mean          | 10           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 203          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 50           |\n",
      "|    total_timesteps      | 256000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012740764 |\n",
      "|    clip_fraction        | 0.00996      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0141      |\n",
      "|    explained_variance   | 0.9384341    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.000181    |\n",
      "|    n_updates            | 1240         |\n",
      "|    policy_gradient_loss | -0.00612     |\n",
      "|    value_loss           | 0.000375     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.03          |\n",
      "|    ep_rew_mean          | 9.8           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 210           |\n",
      "|    iterations           | 6             |\n",
      "|    time_elapsed         | 58            |\n",
      "|    total_timesteps      | 258048        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00071968365 |\n",
      "|    clip_fraction        | 0.00288       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0097       |\n",
      "|    explained_variance   | 0.98986995    |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.000144      |\n",
      "|    n_updates            | 1250          |\n",
      "|    policy_gradient_loss | -0.00443      |\n",
      "|    value_loss           | 0.000121      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4            |\n",
      "|    ep_rew_mean          | 10           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 215          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 66           |\n",
      "|    total_timesteps      | 260096       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005885447 |\n",
      "|    clip_fraction        | 0.0041       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00847     |\n",
      "|    explained_variance   | 0.03191179   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.000632    |\n",
      "|    n_updates            | 1260         |\n",
      "|    policy_gradient_loss | -0.00532     |\n",
      "|    value_loss           | 0.641        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 5.5        |\n",
      "|    ep_rew_mean          | 9.6        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 219        |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 74         |\n",
      "|    total_timesteps      | 262144     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.73110497 |\n",
      "|    clip_fraction        | 0.0765     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0582    |\n",
      "|    explained_variance   | 0.99105746 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0963    |\n",
      "|    n_updates            | 1270       |\n",
      "|    policy_gradient_loss | 0.235      |\n",
      "|    value_loss           | 6.68e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.07        |\n",
      "|    ep_rew_mean          | 10          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 203         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 264192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0351898   |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.32       |\n",
      "|    explained_variance   | 0.012274027 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.7         |\n",
      "|    n_updates            | 1280        |\n",
      "|    policy_gradient_loss | -0.0219     |\n",
      "|    value_loss           | 6.54        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.76        |\n",
      "|    ep_rew_mean          | 10          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 203         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 100         |\n",
      "|    total_timesteps      | 266240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032352936 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.248      |\n",
      "|    explained_variance   | 0.030748308 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.51        |\n",
      "|    n_updates            | 1290        |\n",
      "|    policy_gradient_loss | -0.0238     |\n",
      "|    value_loss           | 2.11        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.24        |\n",
      "|    ep_rew_mean          | 10          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 184         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 122         |\n",
      "|    total_timesteps      | 268288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.12469578  |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.116      |\n",
      "|    explained_variance   | 0.012894928 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0516     |\n",
      "|    n_updates            | 1300        |\n",
      "|    policy_gradient_loss | -0.0335     |\n",
      "|    value_loss           | 0.659       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.03       |\n",
      "|    ep_rew_mean          | 10         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 170        |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 144        |\n",
      "|    total_timesteps      | 270336     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06364299 |\n",
      "|    clip_fraction        | 0.253      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0645    |\n",
      "|    explained_variance   | 0.02028346 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0396    |\n",
      "|    n_updates            | 1310       |\n",
      "|    policy_gradient_loss | -0.0364    |\n",
      "|    value_loss           | 0.656      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.06         |\n",
      "|    ep_rew_mean          | 10           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 159          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 166          |\n",
      "|    total_timesteps      | 272384       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017694371 |\n",
      "|    clip_fraction        | 0.0214       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0409      |\n",
      "|    explained_variance   | 0.8262429    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00383     |\n",
      "|    n_updates            | 1320         |\n",
      "|    policy_gradient_loss | -0.0135      |\n",
      "|    value_loss           | 0.00238      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 10          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 189         |\n",
      "|    total_timesteps      | 274432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009332182 |\n",
      "|    clip_fraction        | 0.0152      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0171     |\n",
      "|    explained_variance   | 0.848833    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00156     |\n",
      "|    n_updates            | 1330        |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    value_loss           | 0.00188     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.53       |\n",
      "|    ep_rew_mean          | 9.8        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 146        |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 209        |\n",
      "|    total_timesteps      | 276480     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05329851 |\n",
      "|    clip_fraction        | 0.402      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.249     |\n",
      "|    explained_variance   | 0.99709696 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0892    |\n",
      "|    n_updates            | 1340       |\n",
      "|    policy_gradient_loss | 0.341      |\n",
      "|    value_loss           | 2.27e-05   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.24         |\n",
      "|    ep_rew_mean          | 10           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 141          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 230          |\n",
      "|    total_timesteps      | 278528       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.056358002  |\n",
      "|    clip_fraction        | 0.303        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.143       |\n",
      "|    explained_variance   | 0.0076773763 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0332      |\n",
      "|    n_updates            | 1350         |\n",
      "|    policy_gradient_loss | -0.0389      |\n",
      "|    value_loss           | 1.31         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 10         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 145        |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 238        |\n",
      "|    total_timesteps      | 280576     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.279522   |\n",
      "|    clip_fraction        | 0.0575     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0109    |\n",
      "|    explained_variance   | 0.89153177 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0878    |\n",
      "|    n_updates            | 1360       |\n",
      "|    policy_gradient_loss | -0.0561    |\n",
      "|    value_loss           | 0.00158    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.28        |\n",
      "|    ep_rew_mean          | 10          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 245         |\n",
      "|    total_timesteps      | 282624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010242842 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0822     |\n",
      "|    explained_variance   | 0.9977461   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0764     |\n",
      "|    n_updates            | 1370        |\n",
      "|    policy_gradient_loss | -0.042      |\n",
      "|    value_loss           | 8.4e-06     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.06        |\n",
      "|    ep_rew_mean          | 10          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 253         |\n",
      "|    total_timesteps      | 284672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.1241516   |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.027      |\n",
      "|    explained_variance   | 0.019615412 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0439     |\n",
      "|    n_updates            | 1380        |\n",
      "|    policy_gradient_loss | -0.0382     |\n",
      "|    value_loss           | 0.656       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 10          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 261         |\n",
      "|    total_timesteps      | 286720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020021897 |\n",
      "|    clip_fraction        | 0.00674     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.00277    |\n",
      "|    explained_variance   | 0.97885364  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00248    |\n",
      "|    n_updates            | 1390        |\n",
      "|    policy_gradient_loss | -0.0092     |\n",
      "|    value_loss           | 0.000266    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 5.02       |\n",
      "|    ep_rew_mean          | 10         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 159        |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 268        |\n",
      "|    total_timesteps      | 288768     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.7098744  |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0588    |\n",
      "|    explained_variance   | 0.99957776 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0933    |\n",
      "|    n_updates            | 1400       |\n",
      "|    policy_gradient_loss | -0.0253    |\n",
      "|    value_loss           | 5.18e-07   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.28        |\n",
      "|    ep_rew_mean          | 5.4         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 163         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 275         |\n",
      "|    total_timesteps      | 290816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.103863396 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.231      |\n",
      "|    explained_variance   | 0.040204227 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0517     |\n",
      "|    n_updates            | 1410        |\n",
      "|    policy_gradient_loss | -0.0328     |\n",
      "|    value_loss           | 0.804       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.33        |\n",
      "|    ep_rew_mean          | 6.6         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 166         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 282         |\n",
      "|    total_timesteps      | 292864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018454656 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.34       |\n",
      "|    explained_variance   | 0.103592694 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.9        |\n",
      "|    n_updates            | 1420        |\n",
      "|    policy_gradient_loss | -0.0455     |\n",
      "|    value_loss           | 48.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.24        |\n",
      "|    ep_rew_mean          | 8.8         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 169         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 290         |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013654835 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.274      |\n",
      "|    explained_variance   | 0.08997238  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.63        |\n",
      "|    n_updates            | 1430        |\n",
      "|    policy_gradient_loss | -0.0395     |\n",
      "|    value_loss           | 29.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.04        |\n",
      "|    ep_rew_mean          | 9.8         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 172         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 297         |\n",
      "|    total_timesteps      | 296960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020192908 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.193      |\n",
      "|    explained_variance   | 0.004029274 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.64        |\n",
      "|    n_updates            | 1440        |\n",
      "|    policy_gradient_loss | -0.0266     |\n",
      "|    value_loss           | 13.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.1         |\n",
      "|    ep_rew_mean          | 10          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 174         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 304         |\n",
      "|    total_timesteps      | 299008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044903237 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.111      |\n",
      "|    explained_variance   | 0.018889308 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.75        |\n",
      "|    n_updates            | 1450        |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    value_loss           | 5.04        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=300000, episode_reward=10.00 +/- 0.00\n",
      "Episode length: 7.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 7          |\n",
      "|    mean_reward          | 10         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 300000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 1.0503104  |\n",
      "|    clip_fraction        | 0.358      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.18      |\n",
      "|    explained_variance   | -2.5431008 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0539    |\n",
      "|    n_updates            | 1460       |\n",
      "|    policy_gradient_loss | -0.0561    |\n",
      "|    value_loss           | 0.0176     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 7.04     |\n",
      "|    ep_rew_mean     | 10       |\n",
      "| time/              |          |\n",
      "|    fps             | 178      |\n",
      "|    iterations      | 27       |\n",
      "|    time_elapsed    | 310      |\n",
      "|    total_timesteps | 301056   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 7.46       |\n",
      "|    ep_rew_mean          | 9.8        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 181        |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 315        |\n",
      "|    total_timesteps      | 303104     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06559493 |\n",
      "|    clip_fraction        | 0.183      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.173     |\n",
      "|    explained_variance   | 0.93680966 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0564    |\n",
      "|    n_updates            | 1470       |\n",
      "|    policy_gradient_loss | 0.0149     |\n",
      "|    value_loss           | 0.00136    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 6.7         |\n",
      "|    ep_rew_mean          | 9.8         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 184         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 321         |\n",
      "|    total_timesteps      | 305152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.06821856  |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.34       |\n",
      "|    explained_variance   | 0.009598732 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0291     |\n",
      "|    n_updates            | 1480        |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    value_loss           | 2.89        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 6.27        |\n",
      "|    ep_rew_mean          | 9.4         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 187         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 327         |\n",
      "|    total_timesteps      | 307200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034364745 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.351      |\n",
      "|    explained_variance   | 0.05502832  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00536    |\n",
      "|    n_updates            | 1490        |\n",
      "|    policy_gradient_loss | -0.0242     |\n",
      "|    value_loss           | 0.65        |\n",
      "-----------------------------------------\n",
      "模型已保存为: ./connectx_models/ppo_60000_300000.zip\n",
      "模型已保存为: ppo_final\n",
      "文件已重命名: ./connectx_models/best_model.zip -> ./connectx_models\\offensive_model.zip\n",
      "文件已重命名: ./connectx_models/offensive_60000_120000.zip -> ./connectx_models\\offensive_60000_120000.zip\n",
      "文件已重命名: ./connectx_models/offensive_60000_180000.zip -> ./connectx_models\\offensive_60000_180000.zip\n",
      "文件已重命名: ./connectx_models/offensive_60000_240000.zip -> ./connectx_models\\offensive_60000_240000.zip\n",
      "文件已重命名: ./connectx_models/offensive_60000_300000.zip -> ./connectx_models\\offensive_60000_300000.zip\n",
      "文件已重命名: ./connectx_models/offensive_60000_60000.zip -> ./connectx_models\\offensive_60000_60000.zip\n",
      "文件已重命名: ./connectx_models/offensive_final.zip -> ./connectx_models\\offensive_final.zip\n",
      "文件已重命名: ./connectx_models/offensive_final_DQN.zip -> ./connectx_models\\offensive_final_DQN.zip\n",
      "文件已重命名: ./connectx_models/offensive_model.zip -> ./connectx_models\\offensive_model.zip\n",
      "文件已重命名: ./connectx_models/ppo_60000_120000.zip -> ./connectx_models\\offensive_60000_120000.zip\n",
      "文件已重命名: ./connectx_models/ppo_60000_180000.zip -> ./connectx_models\\offensive_60000_180000.zip\n",
      "文件已重命名: ./connectx_models/ppo_60000_240000.zip -> ./connectx_models\\offensive_60000_240000.zip\n",
      "文件已重命名: ./connectx_models/ppo_60000_300000.zip -> ./connectx_models\\offensive_60000_300000.zip\n",
      "文件已重命名: ./connectx_models/ppo_60000_60000.zip -> ./connectx_models\\offensive_60000_60000.zip\n",
      "文件已重命名: ./connectx_models/ppo_final.zip -> ./connectx_models\\offensive_final.zip\n"
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "tensorboard_log = \"./connectx_tensorboard/\"\n",
    "if os.path.exists(tensorboard_log):\n",
    "    shutil.rmtree(tensorboard_log)  # 删除旧日志目录\n",
    "trainer = ConnectXTrainer(model_type=\"DQN\", opponent=agent_minmax_2)\n",
    "model, off_model_paths = trainer.train(\n",
    "    total_timesteps=300_000, tensorboard_log=tensorboard_log\n",
    ")\n",
    "rename_models(prefix=\"offensive\", models_path_raw=off_model_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9bb102f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================\n",
      "总回合数: 68087\n",
      "平均奖励: 9.38\n",
      "最高奖励: 10.00\n",
      "最低奖励: -10.00\n",
      "最后100回合平均奖励: 9.40\n"
     ]
    }
   ],
   "source": [
    "trainer.show(window_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "961d6462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型已从 ./connectx_models/offensive_final.zip 加载\n"
     ]
    }
   ],
   "source": [
    "# 正反手测试\n",
    "offensive_model_path = \"./connectx_models/offensive_final.zip\"  # 注意，此处并不固定，可能是best_model更好，也可能的final更好（例如验证策略采用随机指标时，final会更好）\n",
    "global offensive_agent_model\n",
    "offensive_agent_model = load_model(offensive_model_path)\n",
    "\n",
    "def agent(observation, configuration):\n",
    "    \"\"\"Kaggle agent接口，负责动作决策\"\"\"\n",
    "    # 构造观察状态\n",
    "    board = observation.board\n",
    "    current_player = observation.mark\n",
    "    obs = np.array(board + [current_player], dtype=np.int32)\n",
    "\n",
    "    # 获取模型预测\n",
    "    action, _ = offensive_agent_model.predict(\n",
    "        obs, deterministic=True\n",
    "    )  # deterministic表示模型取概率最高的动作（否则会随机）\n",
    "    # 确保动作有效\n",
    "    possible_actions = [c for c in range(configuration.columns) if board[c] == 0]\n",
    "\n",
    "    if action in possible_actions:\n",
    "        return int(action)\n",
    "    else:\n",
    "        # 如果预测动作无效，随机选择一个有效动作\n",
    "        return random.choice(possible_actions) if possible_actions else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee4bb2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型已从 ./offensive_final.zip 加载\n"
     ]
    }
   ],
   "source": [
    "# 正反手测试\n",
    "offensive_model_path_ = \"./offensive_final.zip\"  # 注意，此处并不固定，可能是best_model更好，也可能的final更好（例如验证策略采用随机指标时，final会更好）\n",
    "global offensive_agent_model_\n",
    "offensive_agent_model_ = load_model(offensive_model_path_)\n",
    "\n",
    "\n",
    "def agent_(observation, configuration):\n",
    "    \"\"\"Kaggle agent接口，负责动作决策\"\"\"\n",
    "    # 构造观察状态\n",
    "    board = observation.board\n",
    "    current_player = observation.mark\n",
    "    obs = np.array(board + [current_player], dtype=np.int32)\n",
    "\n",
    "    # 获取模型预测\n",
    "    action, _ = offensive_agent_model_.predict(\n",
    "        obs, deterministic=True\n",
    "    )  # deterministic表示模型取概率最高的动作（否则会随机）\n",
    "    # 确保动作有效\n",
    "    possible_actions = [c for c in range(configuration.columns) if board[c] == 0]\n",
    "\n",
    "    if action in possible_actions:\n",
    "        return int(action)\n",
    "    else:\n",
    "        # 如果预测动作无效，随机选择一个有效动作\n",
    "        return random.choice(possible_actions) if possible_actions else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0aff396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent vs random 胜率（正手）：0.81\n",
      "Agent vs random 胜率（反手）：0.76\n",
      "Agent vs minmax 胜率（正手）：1.0\n",
      "Agent vs minmax 胜率（反手）：0.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Agent vs random 胜率（正手）：{test_win_rate(agent, 'random', num_episodes=100)}\")\n",
    "print(f\"Agent vs random 胜率（反手）：{1- test_win_rate('random', agent, num_episodes=100)}\")\n",
    "print(f\"Agent vs minmax 胜率（正手）：{test_win_rate(agent, agent_minmax_2, num_episodes=100)}\")\n",
    "print(f\"Agent vs minmax 胜率（反手）：{1-test_win_rate(agent_minmax_2, agent, num_episodes=100)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "196694c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent vs random 胜率（正手）：0.77\n",
      "Agent vs random 胜率（反手）：0.85\n",
      "Agent vs minmax 胜率（正手）：1.0\n",
      "Agent vs minmax 胜率（反手）：0.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Agent vs random 胜率（正手）：{test_win_rate(agent_, 'random', num_episodes=100)}\")\n",
    "print(f\"Agent vs random 胜率（反手）：{1- test_win_rate('random', agent_, num_episodes=100)}\")\n",
    "print(f\"Agent vs minmax 胜率（正手）：{test_win_rate(agent_, agent_minmax, num_episodes=100)}\")\n",
    "print(f\"Agent vs minmax 胜率（反手）：{1-test_win_rate(agent_minmax, agent_, num_episodes=100)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "592c26cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent vs minmax 胜率（正手）：0.66\n",
      "Agent vs minmax 胜率（反手）：0.41000000000000003\n"
     ]
    }
   ],
   "source": [
    "print(f\"Agent vs Agent 胜率（正手）：{test_win_rate(agent, agent_, num_episodes=100)}\")\n",
    "print(f\"Agent vs Agent 胜率（反手）：{1-test_win_rate(agent_, agent, num_episodes=100)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a8b60e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型权重已保存到文件 'model_weights.pth'\n",
      "\n",
      "提取的模型权重信息：\n",
      "mlp_extractor.policy_net.0.weight: torch.Size([64, 43])\n",
      "mlp_extractor.policy_net.0.bias: torch.Size([64])\n",
      "mlp_extractor.policy_net.2.weight: torch.Size([64, 64])\n",
      "mlp_extractor.policy_net.2.bias: torch.Size([64])\n",
      "mlp_extractor.value_net.0.weight: torch.Size([64, 43])\n",
      "mlp_extractor.value_net.0.bias: torch.Size([64])\n",
      "mlp_extractor.value_net.2.weight: torch.Size([64, 64])\n",
      "mlp_extractor.value_net.2.bias: torch.Size([64])\n",
      "action_net.weight: torch.Size([7, 64])\n",
      "action_net.bias: torch.Size([7])\n",
      "value_net.weight: torch.Size([1, 64])\n",
      "value_net.bias: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# 提取模型的权重信息\n",
    "state_dict = offensive_agent_model_.policy.to(\"cpu\").state_dict()\n",
    "import torch\n",
    "\n",
    "# 保存权重到文件\n",
    "torch.save(state_dict, \"model_weights.pth\")\n",
    "\n",
    "print(\"模型权重已保存到文件 'model_weights.pth'\")\n",
    "\n",
    "# 打印提取的权重信息\n",
    "print(\"\\n提取的模型权重信息：\")\n",
    "for name, param in state_dict.items():\n",
    "    print(f\"{name}: {param.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03f5d051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn as nn\n",
    "\n",
    "class AgentPPO(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AgentPPO, self).__init__()\n",
    "        # 特征提取器\n",
    "        self.features_extractor = nn.Flatten(start_dim=1, end_dim=-1)\n",
    "        # 策略网络特征提取器\n",
    "        self.pi_features_extractor = nn.Flatten(start_dim=1, end_dim=-1)\n",
    "        # 值网络特征提取器\n",
    "        self.vf_features_extractor = nn.Flatten(start_dim=1, end_dim=-1)\n",
    "        # MLP提取器\n",
    "        self.mlp_extractor = nn.ModuleDict(\n",
    "            {\n",
    "                \"policy_net\": nn.Sequential(\n",
    "                    nn.Linear(43, 64), nn.Tanh(), nn.Linear(64, 64), nn.Tanh()\n",
    "                ),\n",
    "                \"value_net\": nn.Sequential(\n",
    "                    nn.Linear(43, 64), nn.Tanh(), nn.Linear(64, 64), nn.Tanh()\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "        self.action_net = nn.Linear(64, 7)\n",
    "        self.value_net = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 特征提取\n",
    "        x = self.features_extractor(x)\n",
    "        # 策略网络\n",
    "        pi_features = self.pi_features_extractor(x)\n",
    "        policy_output = self.mlp_extractor[\"policy_net\"](pi_features)\n",
    "        action_logits = self.action_net(policy_output)\n",
    "        # 值网络\n",
    "        vf_features = self.vf_features_extractor(x)\n",
    "        value_output = self.mlp_extractor[\"value_net\"](vf_features)\n",
    "        value = self.value_net(value_output)\n",
    "        return action_logits, value\n",
    "\n",
    "\n",
    "# 初始化模型\n",
    "model = AgentPPO()\n",
    "model = model.float()\n",
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        \"model_weights.pth\", map_location=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    )\n",
    ")\n",
    "model = model.to(\"cpu\")\n",
    "model = model.eval()\n",
    "\n",
    "\n",
    "def preprocess_observation(board, mark, configuration):\n",
    "    \"\"\"\n",
    "    本次编写的棋盘接受43维输入  6*7+1\n",
    "    \"\"\"\n",
    "    # 将board转换为6x7的矩阵（ConnectX标准尺寸）\n",
    "    rows, cols = configuration.rows, configuration.columns\n",
    "    board_2d = np.array(board).reshape(rows, cols)\n",
    "\n",
    "    # 创建特征向量（43维）\n",
    "    features = []\n",
    "\n",
    "    # 1. 棋盘状态特征 (展平，42维: 6*7)\n",
    "    board_flat = board_2d.flatten()\n",
    "    features.extend(board_flat)\n",
    "\n",
    "    # 2. 当前玩家标识 (1维)\n",
    "    current_player = mark\n",
    "    features.append(current_player)\n",
    "\n",
    "    return np.array(features, dtype=np.float32)\n",
    "\n",
    "\n",
    "def agent(observation, configuration):\n",
    "    # 获取棋盘状态并预处理为43维\n",
    "    processed_obs = preprocess_observation(\n",
    "        observation[\"board\"], observation.mark, configuration\n",
    "    )\n",
    "    obs_tensor = torch.tensor(processed_obs, dtype=torch.float32).reshape(1, -1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        action_logits, _ = model(obs_tensor)\n",
    "\n",
    "        # 获取有效动作\n",
    "        board_2d = np.array(observation[\"board\"]).reshape(\n",
    "            configuration.rows, configuration.columns\n",
    "        )\n",
    "        valid_actions = []\n",
    "        for col in range(configuration.columns):\n",
    "            if board_2d[0, col] == 0:\n",
    "                valid_actions.append(col)\n",
    "        # 如果没有有效动作，返回随机动作（理论上不应该发生）\n",
    "        if not valid_actions:\n",
    "            return np.random.choice(configuration.columns)\n",
    "        # 只考虑有效动作\n",
    "        action_mask = torch.full((configuration.columns,), float(\"-inf\"))\n",
    "        for valid_action in valid_actions:\n",
    "            action_mask[valid_action] = 0\n",
    "        masked_logits = action_logits.squeeze(0) + action_mask\n",
    "\n",
    "        # 选择最佳动作\n",
    "        action = torch.argmax(masked_logits).item()\n",
    "\n",
    "    return int(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d7e67cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "0.99\n",
      "0.99\n",
      "0.8\n",
      "0.88\n",
      "耗时： 413.38471269607544\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "print(test_win_rate(agent_minmax_3, \"random\", num_episodes=100))\n",
    "print(1 - test_win_rate(\"random\", agent_minmax_3, num_episodes=100))\n",
    "print(test_win_rate(\"negamax\", \"random\", num_episodes=100))\n",
    "print(1 - test_win_rate(\"random\", \"negamax\", num_episodes=100))\n",
    "st1 = time.time()\n",
    "print(test_win_rate(agent_minmax_3, \"negamax\", num_episodes=100))\n",
    "print(1 - test_win_rate(\"negamax\", agent_minmax_3, num_episodes=100))\n",
    "print(\"耗时：\", time.time() - st1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0318039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96\n",
      "0.97\n"
     ]
    }
   ],
   "source": [
    "print(test_win_rate(agent_random, \"random\", num_episodes=100))\n",
    "print(1 - test_win_rate(\"random\", agent_random, num_episodes=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e72aa022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23\n",
      "0.48\n"
     ]
    }
   ],
   "source": [
    "print(test_win_rate(agent_random, \"negamax\", num_episodes=100))\n",
    "print(1 - test_win_rate(\"negamax\", agent_random, num_episodes=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d6c80e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "耗时： 34.6394202709198\n",
      "0.8\n",
      "耗时： 37.06715798377991\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "st1 = time.time()\n",
    "print(test_win_rate(agent_minmax_3, agent_minmax_3, num_episodes=10))\n",
    "print(\"耗时：\", time.time() - st1)\n",
    "st1 = time.time()\n",
    "print(1 - test_win_rate(agent_minmax_4, agent_minmax_4, num_episodes=10))\n",
    "print(\"耗时：\", time.time() - st1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66ccae69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe srcdoc=\"<!--\n",
       "  Copyright 2020 Kaggle Inc\n",
       "\n",
       "  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);\n",
       "  you may not use this file except in compliance with the License.\n",
       "  You may obtain a copy of the License at\n",
       "\n",
       "      http://www.apache.org/licenses/LICENSE-2.0\n",
       "\n",
       "  Unless required by applicable law or agreed to in writing, software\n",
       "  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,\n",
       "  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "  See the License for the specific language governing permissions and\n",
       "  limitations under the License.\n",
       "-->\n",
       "<!DOCTYPE html>\n",
       "<html lang=&quot;en&quot;>\n",
       "  <head>\n",
       "    <title>Kaggle Simulation Player</title>\n",
       "    <meta name=&quot;viewport&quot; content=&quot;width=device-width,initial-scale=1&quot; />\n",
       "    <link\n",
       "      rel=&quot;stylesheet&quot;\n",
       "      href=&quot;https://cdnjs.cloudflare.com/ajax/libs/meyer-reset/2.0/reset.css&quot;\n",
       "      crossorigin=&quot;anonymous&quot;\n",
       "    />\n",
       "    <style type=&quot;text/css&quot;>\n",
       "      html,\n",
       "      body {\n",
       "        height: 100%;\n",
       "        font-family: sans-serif;\n",
       "        margin: 0px;\n",
       "      }\n",
       "      canvas {\n",
       "        /* image-rendering: -moz-crisp-edges;\n",
       "        image-rendering: -webkit-crisp-edges;\n",
       "        image-rendering: pixelated;\n",
       "        image-rendering: crisp-edges; */\n",
       "      }\n",
       "    </style>\n",
       "    <script src=&quot;https://unpkg.com/preact@10.0.1/dist/preact.umd.js&quot;></script>\n",
       "    <script src=&quot;https://unpkg.com/preact@10.0.1/hooks/dist/hooks.umd.js&quot;></script>\n",
       "    <script src=&quot;https://unpkg.com/htm@2.2.1/dist/htm.umd.js&quot;></script>\n",
       "    <script src=&quot;https://unpkg.com/chess.js@0.12.0/chess.js&quot;></script>\n",
       "    <script>\n",
       "      // Polyfill for Styled Components\n",
       "      window.React = {\n",
       "        ...preact,\n",
       "        createElement: preact.h,\n",
       "        PropTypes: { func: {} },\n",
       "      };\n",
       "    </script>\n",
       "    <script src=&quot;https://unpkg.com/styled-components@3.5.0-0/dist/styled-components.min.js&quot;></script>\n",
       "  </head>\n",
       "  <body>\n",
       "    <script>\n",
       "      \n",
       "window.kaggle = {\n",
       "  &quot;debug&quot;: true,\n",
       "  &quot;playing&quot;: true,\n",
       "  &quot;step&quot;: 0,\n",
       "  &quot;controls&quot;: true,\n",
       "  &quot;environment&quot;: {\n",
       "    &quot;id&quot;: &quot;40dd33f0-49b3-11f0-8261-703217d4c5ed&quot;,\n",
       "    &quot;name&quot;: &quot;connectx&quot;,\n",
       "    &quot;title&quot;: &quot;ConnectX&quot;,\n",
       "    &quot;description&quot;: &quot;Classic Connect in a row but configurable.&quot;,\n",
       "    &quot;version&quot;: &quot;1.0.1&quot;,\n",
       "    &quot;configuration&quot;: {\n",
       "      &quot;episodeSteps&quot;: 1000,\n",
       "      &quot;actTimeout&quot;: 2,\n",
       "      &quot;runTimeout&quot;: 1200,\n",
       "      &quot;columns&quot;: 7,\n",
       "      &quot;rows&quot;: 6,\n",
       "      &quot;inarow&quot;: 4,\n",
       "      &quot;agentTimeout&quot;: 60,\n",
       "      &quot;timeout&quot;: 2\n",
       "    },\n",
       "    &quot;specification&quot;: {\n",
       "      &quot;action&quot;: {\n",
       "        &quot;description&quot;: &quot;Column to drop a checker onto the board.&quot;,\n",
       "        &quot;type&quot;: &quot;integer&quot;,\n",
       "        &quot;minimum&quot;: 0,\n",
       "        &quot;default&quot;: 0\n",
       "      },\n",
       "      &quot;agents&quot;: [\n",
       "        2\n",
       "      ],\n",
       "      &quot;configuration&quot;: {\n",
       "        &quot;episodeSteps&quot;: {\n",
       "          &quot;description&quot;: &quot;Maximum number of steps in the episode.&quot;,\n",
       "          &quot;type&quot;: &quot;integer&quot;,\n",
       "          &quot;minimum&quot;: 1,\n",
       "          &quot;default&quot;: 1000\n",
       "        },\n",
       "        &quot;actTimeout&quot;: {\n",
       "          &quot;description&quot;: &quot;Maximum runtime (seconds) to obtain an action from an agent.&quot;,\n",
       "          &quot;type&quot;: &quot;number&quot;,\n",
       "          &quot;minimum&quot;: 0,\n",
       "          &quot;default&quot;: 2\n",
       "        },\n",
       "        &quot;runTimeout&quot;: {\n",
       "          &quot;description&quot;: &quot;Maximum runtime (seconds) of an episode (not necessarily DONE).&quot;,\n",
       "          &quot;type&quot;: &quot;number&quot;,\n",
       "          &quot;minimum&quot;: 0,\n",
       "          &quot;default&quot;: 1200\n",
       "        },\n",
       "        &quot;columns&quot;: {\n",
       "          &quot;description&quot;: &quot;The number of columns on the board&quot;,\n",
       "          &quot;type&quot;: &quot;integer&quot;,\n",
       "          &quot;default&quot;: 7,\n",
       "          &quot;minimum&quot;: 1\n",
       "        },\n",
       "        &quot;rows&quot;: {\n",
       "          &quot;description&quot;: &quot;The number of rows on the board&quot;,\n",
       "          &quot;type&quot;: &quot;integer&quot;,\n",
       "          &quot;default&quot;: 6,\n",
       "          &quot;minimum&quot;: 1\n",
       "        },\n",
       "        &quot;inarow&quot;: {\n",
       "          &quot;description&quot;: &quot;The number of checkers in a row required to win.&quot;,\n",
       "          &quot;type&quot;: &quot;integer&quot;,\n",
       "          &quot;default&quot;: 4,\n",
       "          &quot;minimum&quot;: 1\n",
       "        },\n",
       "        &quot;agentTimeout&quot;: {\n",
       "          &quot;description&quot;: &quot;Obsolete field kept for backwards compatibility, please use observation.remainingOverageTime.&quot;,\n",
       "          &quot;type&quot;: &quot;number&quot;,\n",
       "          &quot;minimum&quot;: 0,\n",
       "          &quot;default&quot;: 60\n",
       "        },\n",
       "        &quot;timeout&quot;: {\n",
       "          &quot;description&quot;: &quot;Obsolete copy of actTimeout maintained for backwards compatibility. May be removed in the future.&quot;,\n",
       "          &quot;type&quot;: &quot;integer&quot;,\n",
       "          &quot;default&quot;: 2,\n",
       "          &quot;minimum&quot;: 0\n",
       "        }\n",
       "      },\n",
       "      &quot;info&quot;: {},\n",
       "      &quot;observation&quot;: {\n",
       "        &quot;remainingOverageTime&quot;: {\n",
       "          &quot;description&quot;: &quot;Total remaining banked time (seconds) that can be used in excess of per-step actTimeouts -- agent is disqualified with TIMEOUT status when this drops below 0.&quot;,\n",
       "          &quot;shared&quot;: false,\n",
       "          &quot;type&quot;: &quot;number&quot;,\n",
       "          &quot;minimum&quot;: 0,\n",
       "          &quot;default&quot;: 60\n",
       "        },\n",
       "        &quot;step&quot;: {\n",
       "          &quot;description&quot;: &quot;Current step within the episode.&quot;,\n",
       "          &quot;type&quot;: &quot;integer&quot;,\n",
       "          &quot;shared&quot;: true,\n",
       "          &quot;minimum&quot;: 0,\n",
       "          &quot;default&quot;: 0\n",
       "        },\n",
       "        &quot;board&quot;: {\n",
       "          &quot;description&quot;: &quot;Serialized grid (rows x columns). 0 = Empty, 1 = P1, 2 = P2&quot;,\n",
       "          &quot;type&quot;: &quot;array&quot;,\n",
       "          &quot;shared&quot;: true,\n",
       "          &quot;default&quot;: []\n",
       "        },\n",
       "        &quot;mark&quot;: {\n",
       "          &quot;defaults&quot;: [\n",
       "            1,\n",
       "            2\n",
       "          ],\n",
       "          &quot;description&quot;: &quot;Which checkers are the agents.&quot;,\n",
       "          &quot;enum&quot;: [\n",
       "            1,\n",
       "            2\n",
       "          ]\n",
       "        }\n",
       "      },\n",
       "      &quot;reward&quot;: {\n",
       "        &quot;description&quot;: &quot;-1 = Lost, 0 = Draw/Ongoing, 1 = Won&quot;,\n",
       "        &quot;enum&quot;: [\n",
       "          -1,\n",
       "          0,\n",
       "          1\n",
       "        ],\n",
       "        &quot;default&quot;: 0,\n",
       "        &quot;type&quot;: [\n",
       "          &quot;number&quot;,\n",
       "          &quot;null&quot;\n",
       "        ]\n",
       "      }\n",
       "    },\n",
       "    &quot;steps&quot;: [\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 0,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 5,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 1,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 2,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              0\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 3,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 4,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 3,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              1,\n",
       "              1,\n",
       "              0\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 4,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              1,\n",
       "              1,\n",
       "              0\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 4,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 5,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              1,\n",
       "              1,\n",
       "              0\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 6,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              2,\n",
       "              0,\n",
       "              2,\n",
       "              1,\n",
       "              1,\n",
       "              0\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 1,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 2,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 7,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2,\n",
       "              1,\n",
       "              1,\n",
       "              0\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 8,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2,\n",
       "              1,\n",
       "              1,\n",
       "              2\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 6,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 6,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 9,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2,\n",
       "              1,\n",
       "              1,\n",
       "              2\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 10,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2,\n",
       "              1,\n",
       "              1,\n",
       "              2\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 2,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 1,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 11,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2,\n",
       "              1,\n",
       "              1,\n",
       "              2\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 12,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2,\n",
       "              1,\n",
       "              1,\n",
       "              2\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 6,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 4,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 13,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2,\n",
       "              1,\n",
       "              1,\n",
       "              2\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 14,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2,\n",
       "              1,\n",
       "              1,\n",
       "              2\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 4,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 4,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 15,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2,\n",
       "              1,\n",
       "              1,\n",
       "              2\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 16,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2,\n",
       "              1,\n",
       "              1,\n",
       "              2\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 3,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 3,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 17,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              1,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2,\n",
       "              1,\n",
       "              1,\n",
       "              2\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 18,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              1,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2,\n",
       "              1,\n",
       "              1,\n",
       "              2\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 5,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 6,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 19,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              1,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2,\n",
       "              1,\n",
       "              1,\n",
       "              2\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 20,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              1,\n",
       "              0,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2,\n",
       "              1,\n",
       "              1,\n",
       "              2\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 2,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 21,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              1,\n",
       "              1,\n",
       "              0,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2,\n",
       "              1,\n",
       "              1,\n",
       "              2\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 22,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              2,\n",
       "              1,\n",
       "              1,\n",
       "              1,\n",
       "              0,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2,\n",
       "              1,\n",
       "              1,\n",
       "              2\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 1,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 2,\n",
       "          &quot;reward&quot;: 1,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 23,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              2,\n",
       "              1,\n",
       "              1,\n",
       "              1,\n",
       "              0,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2,\n",
       "              1,\n",
       "              1,\n",
       "              2\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;DONE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: -1,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;DONE&quot;\n",
       "        }\n",
       "      ]\n",
       "    ],\n",
       "    &quot;rewards&quot;: [\n",
       "      1,\n",
       "      -1\n",
       "    ],\n",
       "    &quot;statuses&quot;: [\n",
       "      &quot;DONE&quot;,\n",
       "      &quot;DONE&quot;\n",
       "    ],\n",
       "    &quot;schema_version&quot;: 1,\n",
       "    &quot;info&quot;: {}\n",
       "  },\n",
       "  &quot;logs&quot;: [\n",
       "    [],\n",
       "    [],\n",
       "    [\n",
       "      {\n",
       "        &quot;duration&quot;: 0.000602,\n",
       "        &quot;stdout&quot;: &quot;&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      },\n",
       "      {}\n",
       "    ],\n",
       "    [\n",
       "      {},\n",
       "      {\n",
       "        &quot;duration&quot;: 0.000653,\n",
       "        &quot;stdout&quot;: &quot;&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      }\n",
       "    ],\n",
       "    [\n",
       "      {\n",
       "        &quot;duration&quot;: 0.000765,\n",
       "        &quot;stdout&quot;: &quot;&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      },\n",
       "      {}\n",
       "    ],\n",
       "    [\n",
       "      {},\n",
       "      {\n",
       "        &quot;duration&quot;: 0.00084,\n",
       "        &quot;stdout&quot;: &quot;&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      }\n",
       "    ],\n",
       "    [\n",
       "      {\n",
       "        &quot;duration&quot;: 0.000896,\n",
       "        &quot;stdout&quot;: &quot;&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      },\n",
       "      {}\n",
       "    ],\n",
       "    [\n",
       "      {},\n",
       "      {\n",
       "        &quot;duration&quot;: 0.001291,\n",
       "        &quot;stdout&quot;: &quot;&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      }\n",
       "    ],\n",
       "    [\n",
       "      {\n",
       "        &quot;duration&quot;: 0.001125,\n",
       "        &quot;stdout&quot;: &quot;&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      },\n",
       "      {}\n",
       "    ],\n",
       "    [\n",
       "      {},\n",
       "      {\n",
       "        &quot;duration&quot;: 0.00128,\n",
       "        &quot;stdout&quot;: &quot;&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      }\n",
       "    ],\n",
       "    [\n",
       "      {\n",
       "        &quot;duration&quot;: 0.001363,\n",
       "        &quot;stdout&quot;: &quot;&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      },\n",
       "      {}\n",
       "    ],\n",
       "    [\n",
       "      {},\n",
       "      {\n",
       "        &quot;duration&quot;: 0.001864,\n",
       "        &quot;stdout&quot;: &quot;&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      }\n",
       "    ],\n",
       "    [\n",
       "      {\n",
       "        &quot;duration&quot;: 0.001632,\n",
       "        &quot;stdout&quot;: &quot;&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      },\n",
       "      {}\n",
       "    ],\n",
       "    [\n",
       "      {},\n",
       "      {\n",
       "        &quot;duration&quot;: 0.001763,\n",
       "        &quot;stdout&quot;: &quot;&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      }\n",
       "    ],\n",
       "    [\n",
       "      {\n",
       "        &quot;duration&quot;: 0.002189,\n",
       "        &quot;stdout&quot;: &quot;&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      },\n",
       "      {}\n",
       "    ],\n",
       "    [\n",
       "      {},\n",
       "      {\n",
       "        &quot;duration&quot;: 0.001844,\n",
       "        &quot;stdout&quot;: &quot;&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      }\n",
       "    ],\n",
       "    [\n",
       "      {\n",
       "        &quot;duration&quot;: 0.002138,\n",
       "        &quot;stdout&quot;: &quot;&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      },\n",
       "      {}\n",
       "    ],\n",
       "    [\n",
       "      {},\n",
       "      {\n",
       "        &quot;duration&quot;: 0.002298,\n",
       "        &quot;stdout&quot;: &quot;&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      }\n",
       "    ],\n",
       "    [\n",
       "      {\n",
       "        &quot;duration&quot;: 0.002025,\n",
       "        &quot;stdout&quot;: &quot;&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      },\n",
       "      {}\n",
       "    ],\n",
       "    [\n",
       "      {},\n",
       "      {\n",
       "        &quot;duration&quot;: 0.002368,\n",
       "        &quot;stdout&quot;: &quot;&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      }\n",
       "    ],\n",
       "    [\n",
       "      {\n",
       "        &quot;duration&quot;: 0.003518,\n",
       "        &quot;stdout&quot;: &quot;&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      },\n",
       "      {}\n",
       "    ],\n",
       "    [\n",
       "      {},\n",
       "      {\n",
       "        &quot;duration&quot;: 0.002906,\n",
       "        &quot;stdout&quot;: &quot;&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      }\n",
       "    ],\n",
       "    [\n",
       "      {\n",
       "        &quot;duration&quot;: 0.002878,\n",
       "        &quot;stdout&quot;: &quot;&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      },\n",
       "      {}\n",
       "    ],\n",
       "    [\n",
       "      {},\n",
       "      {\n",
       "        &quot;duration&quot;: 0.001881,\n",
       "        &quot;stdout&quot;: &quot;&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      }\n",
       "    ],\n",
       "    [\n",
       "      {\n",
       "        &quot;duration&quot;: 0.001982,\n",
       "        &quot;stdout&quot;: &quot;&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      },\n",
       "      {}\n",
       "    ]\n",
       "  ],\n",
       "  &quot;mode&quot;: &quot;ipython&quot;,\n",
       "  &quot;width&quot;: 600,\n",
       "  &quot;height&quot;: 500,\n",
       "  &quot;header&quot;: false\n",
       "};\n",
       "\n",
       "\n",
       "window.kaggle.renderer = // Copyright 2020 Kaggle Inc\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an &quot;AS IS&quot; BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "function renderer({\n",
       "  act,\n",
       "  agents,\n",
       "  environment,\n",
       "  frame,\n",
       "  height = 400,\n",
       "  interactive,\n",
       "  isInteractive,\n",
       "  parent,\n",
       "  step,\n",
       "  update,\n",
       "  width = 400,\n",
       "}) {\n",
       "  // Configuration.\n",
       "  const { rows, columns, inarow } = environment.configuration;\n",
       "\n",
       "  // Common Dimensions.\n",
       "  const unit = 8;\n",
       "  const minCanvasSize = Math.min(height, width);\n",
       "  const minOffset = minCanvasSize > 400 ? 30 : unit / 2;\n",
       "  const cellSize = Math.min(\n",
       "    (width - minOffset * 2) / columns,\n",
       "    (height - minOffset * 2) / rows\n",
       "  );\n",
       "  const cellInset = 0.8;\n",
       "  const pieceScale = cellSize / 100;\n",
       "  const xOffset = Math.max(0, (width - cellSize * columns) / 2);\n",
       "  const yOffset = Math.max(0, (height - cellSize * rows) / 2);\n",
       "\n",
       "  // Canvas Setup.\n",
       "  let canvas = parent.querySelector(&quot;canvas&quot;);\n",
       "  if (!canvas) {\n",
       "    canvas = document.createElement(&quot;canvas&quot;);\n",
       "    parent.appendChild(canvas);\n",
       "\n",
       "    if (interactive) {\n",
       "      canvas.addEventListener(&quot;click&quot;, evt => {\n",
       "        if (!isInteractive()) return;\n",
       "        const rect = evt.target.getBoundingClientRect();\n",
       "        const col = Math.floor((evt.clientX - rect.left - xOffset) / cellSize);\n",
       "        if (col >= 0 && col < columns) act(col);\n",
       "      });\n",
       "    }\n",
       "  }\n",
       "  canvas.style.cursor = isInteractive() ? &quot;pointer&quot; : &quot;default&quot;;\n",
       "\n",
       "  // Character Paths (based on 100x100 tiles).\n",
       "  const kPath = new Path2D(\n",
       "    `M78.3,96.5c-0.1,0.4-0.5,0.6-1.1,0.6H64.9c-0.7,0-1.4-0.3-1.9-1l-20.3-26L37,75.5v20.1 c0,0.9-0.5,1.4-1.4,1.4H26c-0.9,0-1.4-0.5-1.4-1.4V3.9c0-0.9,0.5-1.4,1.4-1.4h9.5C36.5,2.5,37,3,37,3.9v56.5l24.3-24.7 c0.6-0.6,1.3-1,1.9-1H76c0.6,0,0.9,0.2,1.1,0.7c0.2,0.6,0.1,1-0.1,1.2l-25.7,25L78,95.1C78.4,95.5,78.5,95.9,78.3,96.5z`\n",
       "  );\n",
       "  const goose1Path = new Path2D(\n",
       "    `M8.8,92.7c-4-18.5,4.7-37.2,20.7-46.2c0,0,2.7-1.4,3.4-1.9c2.2-1.6,3-2.1,3-5c0-5-2.1-7.2-2.1-7.2 c-3.9-3.3-6.3-8.2-6.3-13.7c0-10,8.1-18.1,18.1-18.1s18.1,8.1,18.1,18.1c0,6-1.5,32.7-2.3,38.8l-0.1,1`\n",
       "  );\n",
       "  const goose2Path = new Path2D(\n",
       "    `M27.4,19L8.2,27.6c0,0-7.3,2.9,2.6,5c6.1,1.3,24,5.9,24,5.9l1,0.3`\n",
       "  );\n",
       "  const goose3Path = new Path2D(\n",
       "    `M63.7,99.6C52.3,99.6,43,90.3,43,78.9s9.3-20.7,20.7-20.7c10.6,0,34.4,0.1,35.8,9`\n",
       "  );\n",
       "\n",
       "  // Canvas setup and reset.\n",
       "  let c = canvas.getContext(&quot;2d&quot;);\n",
       "  canvas.width = width;\n",
       "  canvas.height = height;\n",
       "  c.fillStyle = &quot;#000B2A&quot;;\n",
       "  c.fillRect(0, 0, canvas.width, canvas.height);\n",
       "\n",
       "  const getRowCol = cell => [Math.floor(cell / columns), cell % columns];\n",
       "\n",
       "  const getColor = (mark, opacity = 1) => {\n",
       "    if (mark === 1) return `rgba(0,255,255,${opacity})`;\n",
       "    if (mark === 2) return `rgba(255,255,255,${opacity})`;\n",
       "    return &quot;#fff&quot;;\n",
       "  };\n",
       "\n",
       "  const drawCellCircle = (cell, xFrame = 1, yFrame = 1, radiusOffset = 0) => {\n",
       "    const [row, col] = getRowCol(cell);\n",
       "    c.arc(\n",
       "      xOffset + xFrame * (col * cellSize + cellSize / 2),\n",
       "      yOffset + yFrame * (row * cellSize + cellSize / 2),\n",
       "      (cellInset * cellSize) / 2 - radiusOffset,\n",
       "      2 * Math.PI,\n",
       "      false\n",
       "    );\n",
       "  };\n",
       "\n",
       "  // Render the pieces.\n",
       "  const board = environment.steps[step][0].observation.board;\n",
       "\n",
       "  const drawPiece = mark => {\n",
       "    // Base Styles.\n",
       "    const opacity = minCanvasSize < 300 ? 0.6 - minCanvasSize / 1000 : 0.1;\n",
       "    c.fillStyle = getColor(mark, opacity);\n",
       "    c.strokeStyle = getColor(mark);\n",
       "    c.shadowColor = getColor(mark);\n",
       "    c.shadowBlur = 8 / cellInset;\n",
       "    c.lineWidth = 1 / cellInset;\n",
       "\n",
       "    // Outer circle.\n",
       "    c.save();\n",
       "    c.beginPath();\n",
       "    c.arc(50, 50, 50, 2 * Math.PI, false);\n",
       "    c.closePath();\n",
       "    c.lineWidth *= 4;\n",
       "    c.stroke();\n",
       "    c.fill();\n",
       "    c.restore();\n",
       "\n",
       "    // Inner circle.\n",
       "    c.beginPath();\n",
       "    c.arc(50, 50, 40, 2 * Math.PI, false);\n",
       "    c.closePath();\n",
       "    c.stroke();\n",
       "\n",
       "    // Kaggle &quot;K&quot;.\n",
       "    if (mark === 1) {\n",
       "      const scale = 0.54;\n",
       "      c.save();\n",
       "      c.translate(23, 23);\n",
       "      c.scale(scale, scale);\n",
       "      c.lineWidth /= scale;\n",
       "      c.shadowBlur /= scale;\n",
       "      c.stroke(kPath);\n",
       "      c.restore();\n",
       "    }\n",
       "\n",
       "    // Kaggle &quot;Goose&quot;.\n",
       "    if (mark === 2) {\n",
       "      const scale = 0.6;\n",
       "      c.save();\n",
       "      c.translate(24, 28);\n",
       "      c.scale(scale, scale);\n",
       "      c.lineWidth /= scale;\n",
       "      c.shadowBlur /= scale;\n",
       "      c.stroke(goose1Path);\n",
       "      c.stroke(goose2Path);\n",
       "      c.stroke(goose3Path);\n",
       "      c.beginPath();\n",
       "      c.arc(38.5, 18.6, 2.7, 0, Math.PI * 2, false);\n",
       "      c.closePath();\n",
       "      c.fill();\n",
       "      c.restore();\n",
       "    }\n",
       "  };\n",
       "\n",
       "  for (let i = 0; i < board.length; i++) {\n",
       "    const [row, col] = getRowCol(i);\n",
       "    if (board[i] === 0) continue;\n",
       "    // Easing In.\n",
       "    let yFrame = Math.min(\n",
       "      (columns * Math.pow(frame, 3)) / Math.floor(i / columns),\n",
       "      1\n",
       "    );\n",
       "\n",
       "    if (\n",
       "      step > 1 &&\n",
       "      environment.steps[step - 1][0].observation.board[i] === board[i]\n",
       "    ) {\n",
       "      yFrame = 1;\n",
       "    }\n",
       "\n",
       "    c.save();\n",
       "    c.translate(\n",
       "      xOffset + cellSize * col + (cellSize - cellSize * cellInset) / 2,\n",
       "      yOffset +\n",
       "        yFrame * (cellSize * row) +\n",
       "        (cellSize - cellSize * cellInset) / 2\n",
       "    );\n",
       "    c.scale(pieceScale * cellInset, pieceScale * cellInset);\n",
       "    drawPiece(board[i]);\n",
       "    c.restore();\n",
       "  }\n",
       "\n",
       "  // Background Gradient.\n",
       "  const bgRadius = (Math.min(rows, columns) * cellSize) / 2;\n",
       "  const bgStyle = c.createRadialGradient(\n",
       "    xOffset + (cellSize * columns) / 2,\n",
       "    yOffset + (cellSize * rows) / 2,\n",
       "    0,\n",
       "    xOffset + (cellSize * columns) / 2,\n",
       "    yOffset + (cellSize * rows) / 2,\n",
       "    bgRadius\n",
       "  );\n",
       "  bgStyle.addColorStop(0, &quot;#000B49&quot;);\n",
       "  bgStyle.addColorStop(1, &quot;#000B2A&quot;);\n",
       "\n",
       "  // Render the board overlay.\n",
       "  c.beginPath();\n",
       "  c.rect(0, 0, canvas.width, canvas.height);\n",
       "  c.closePath();\n",
       "  c.shadowBlur = 0;\n",
       "  for (let i = 0; i < board.length; i++) {\n",
       "    drawCellCircle(i);\n",
       "    c.closePath();\n",
       "  }\n",
       "  c.fillStyle = bgStyle;\n",
       "  c.fill(&quot;evenodd&quot;);\n",
       "\n",
       "  // Render the board overlay cell outlines.\n",
       "  for (let i = 0; i < board.length; i++) {\n",
       "    c.beginPath();\n",
       "    drawCellCircle(i);\n",
       "    c.strokeStyle = &quot;#0361B2&quot;;\n",
       "    c.lineWidth = 1;\n",
       "    c.stroke();\n",
       "    c.closePath();\n",
       "  }\n",
       "\n",
       "  const drawLine = (fromCell, toCell) => {\n",
       "    if (frame < 0.5) return;\n",
       "    const lineFrame = (frame - 0.5) / 0.5;\n",
       "    const x1 = xOffset + (fromCell % columns) * cellSize + cellSize / 2;\n",
       "    const x2 =\n",
       "      x1 +\n",
       "      lineFrame *\n",
       "        (xOffset + ((toCell % columns) * cellSize + cellSize / 2) - x1);\n",
       "    const y1 =\n",
       "      yOffset + Math.floor(fromCell / columns) * cellSize + cellSize / 2;\n",
       "    const y2 =\n",
       "      y1 +\n",
       "      lineFrame *\n",
       "        (yOffset + Math.floor(toCell / columns) * cellSize + cellSize / 2 - y1);\n",
       "    c.beginPath();\n",
       "    c.lineCap = &quot;round&quot;;\n",
       "    c.lineWidth = 4;\n",
       "    c.strokeStyle = getColor(board[fromCell]);\n",
       "    c.shadowBlur = 8;\n",
       "    c.shadowColor = getColor(board[fromCell]);\n",
       "    c.moveTo(x1, y1);\n",
       "    c.lineTo(x2, y2);\n",
       "    c.stroke();\n",
       "  };\n",
       "\n",
       "  // Generate a graph of the board.\n",
       "  const getCell = (cell, rowOffset, columnOffset) => {\n",
       "    const row = Math.floor(cell / columns) + rowOffset;\n",
       "    const col = (cell % columns) + columnOffset;\n",
       "    if (row < 0 || row >= rows || col < 0 || col >= columns) return -1;\n",
       "    return col + row * columns;\n",
       "  };\n",
       "  const makeNode = cell => {\n",
       "    const node = { cell, directions: [], value: board[cell] };\n",
       "    for (let r = -1; r <= 1; r++) {\n",
       "      for (let c = -1; c <= 1; c++) {\n",
       "        if (r === 0 && c === 0) continue;\n",
       "        node.directions.push(getCell(cell, r, c));\n",
       "      }\n",
       "    }\n",
       "    return node;\n",
       "  };\n",
       "  const graph = board.map((_, i) => makeNode(i));\n",
       "\n",
       "  // Check for any wins!\n",
       "  const getSequence = (node, direction) => {\n",
       "    const sequence = [node.cell];\n",
       "    while (sequence.length < inarow) {\n",
       "      const next = graph[node.directions[direction]];\n",
       "      if (!next || node.value !== next.value || next.value === 0) return;\n",
       "      node = next;\n",
       "      sequence.push(node.cell);\n",
       "    }\n",
       "    return sequence;\n",
       "  };\n",
       "\n",
       "  // Check all nodes.\n",
       "  for (let i = 0; i < board.length; i++) {\n",
       "    // Check all directions (not the most efficient).\n",
       "    for (let d = 0; d < 8; d++) {\n",
       "      const seq = getSequence(graph[i], d);\n",
       "      if (seq) {\n",
       "        drawLine(seq[0], seq[inarow - 1]);\n",
       "        i = board.length;\n",
       "        break;\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "\n",
       "  // Upgrade the legend.\n",
       "  if (agents.length && (!agents[0].color || !agents[0].image)) {\n",
       "    const getPieceImage = mark => {\n",
       "      const pieceCanvas = document.createElement(&quot;canvas&quot;);\n",
       "      parent.appendChild(pieceCanvas);\n",
       "      pieceCanvas.style.marginLeft = &quot;10000px&quot;;\n",
       "      pieceCanvas.width = 100;\n",
       "      pieceCanvas.height = 100;\n",
       "      c = pieceCanvas.getContext(&quot;2d&quot;);\n",
       "      c.translate(10, 10);\n",
       "      c.scale(0.8, 0.8);\n",
       "      drawPiece(mark);\n",
       "      const dataUrl = pieceCanvas.toDataURL();\n",
       "      parent.removeChild(pieceCanvas);\n",
       "      return dataUrl;\n",
       "    };\n",
       "\n",
       "    agents.forEach(agent => {\n",
       "      agent.color = getColor(agent.index + 1);\n",
       "      agent.image = getPieceImage(agent.index + 1);\n",
       "    });\n",
       "    update({ agents });\n",
       "  }\n",
       "};\n",
       "\n",
       "\n",
       "    \n",
       "    </script>\n",
       "    <script>\n",
       "      const h = htm.bind(preact.h);\n",
       "      const { useContext, useEffect, useRef, useState } = preactHooks;\n",
       "      const styled = window.styled.default;\n",
       "\n",
       "      const Context = preact.createContext({});\n",
       "\n",
       "      const Loading = styled.div`\n",
       "        animation: rotate360 1.1s infinite linear;\n",
       "        border: 8px solid rgba(255, 255, 255, 0.2);\n",
       "        border-left-color: #0cb1ed;\n",
       "        border-radius: 50%;\n",
       "        height: 40px;\n",
       "        position: relative;\n",
       "        transform: translateZ(0);\n",
       "        width: 40px;\n",
       "\n",
       "        @keyframes rotate360 {\n",
       "          0% {\n",
       "            transform: rotate(0deg);\n",
       "          }\n",
       "          100% {\n",
       "            transform: rotate(360deg);\n",
       "          }\n",
       "        }\n",
       "      `;\n",
       "\n",
       "      const Logo = styled(\n",
       "        (props) => h`\n",
       "        <a href=&quot;https://kaggle.com&quot; target=&quot;_blank&quot; className=${props.className}>\n",
       "          <svg width=&quot;62px&quot; height=&quot;20px&quot; viewBox=&quot;0 0 62 24&quot; version=&quot;1.1&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;>\n",
       "            <g fill=&quot;#1EBEFF&quot; fill-rule=&quot;nonzero&quot;>\n",
       "              <path d=&quot;M10.2,17.8c0,0.1-0.1,0.1-0.2,0.1H7.7c-0.1,0-0.3-0.1-0.4-0.2l-3.8-4.9l-1.1,1v3.8 c0,0.2-0.1,0.3-0.3,0.3H0.3c-0.2,0-0.3-0.1-0.3-0.3V0.3C0.1,0.1,0.2,0,0.3,0h1.8c0.2,0,0.3,0.1,0.3,0.3V11L7,6.3 c0.1-0.1,0.2-0.2,0.4-0.2h2.4c0.1,0,0.2,0,0.2,0.1c0,0.1,0,0.2,0,0.2l-4.9,4.7l5.1,6.3C10.2,17.6,10.2,17.7,10.2,17.8z&quot;/>\n",
       "              <path d=&quot;M19.6,17.9h-1.8c-0.2,0-0.3-0.1-0.3-0.3v-0.4c-0.8,0.6-1.8,0.9-3,0.9c-1.1,0-2-0.3-2.8-1 c-0.8-0.7-1.2-1.6-1.2-2.7c0-1.7,1.1-2.9,3.2-3.5c0.8-0.2,2.1-0.5,3.8-0.6c0.1-0.6-0.1-1.2-0.5-1.7c-0.4-0.5-1-0.7-1.7-0.7 c-1,0-2,0.4-3,1C12.2,9.1,12.1,9.1,12,9l-0.9-1.3C11,7.5,11,7.4,11.1,7.3c1.3-0.9,2.7-1.4,4.2-1.4c1.1,0,2.1,0.3,2.8,0.8 c1.1,0.8,1.7,2,1.7,3.7v7.3C19.9,17.8,19.8,17.9,19.6,17.9z M17.5,12.4c-1.7,0.2-2.9,0.4-3.5,0.7c-0.9,0.4-1.2,0.9-1.1,1.6 c0.1,0.4,0.2,0.7,0.6,0.9c0.3,0.2,0.7,0.4,1.1,0.4c1.2,0.1,2.2-0.2,2.9-1V12.4z&quot;/>\n",
       "              <path d=&quot;M30.6,22.5c-0.9,1-2.3,1.5-4,1.5c-1,0-2-0.3-2.9-0.8c-0.2-0.1-0.4-0.3-0.7-0.5 c-0.3-0.2-0.6-0.5-0.9-0.7c-0.1-0.1-0.1-0.2,0-0.4l1.2-1.2c0.1-0.1,0.1-0.1,0.2-0.1c0.1,0,0.1,0,0.2,0.1c1,1,1.9,1.5,2.8,1.5 c2.1,0,3.2-1.1,3.2-3.3v-1.4c-0.8,0.7-1.9,1-3.3,1c-1.7,0-3-0.6-4-1.9c-0.8-1.1-1.3-2.5-1.3-4.2c0-1.6,0.4-3,1.2-4.1 c0.9-1.3,2.3-2,4-2c1.3,0,2.4,0.3,3.3,1V6.4c0-0.2,0.1-0.3,0.3-0.3h1.8c0.2,0,0.3,0.1,0.3,0.3v11.7C32,20,31.5,21.5,30.6,22.5z M29.7,9.9c-0.4-1.1-1.4-1.7-3-1.7c-2,0-3.1,1.3-3.1,3.8c0,1.4,0.3,2.4,1,3.1c0.5,0.5,1.2,0.8,2,0.8c1.6,0,2.7-0.6,3.1-1.7V9.9z&quot;/>\n",
       "              <path d=&quot;M42.9,22.5c-0.9,1-2.3,1.5-4,1.5c-1,0-2-0.3-2.9-0.8c-0.2-0.1-0.4-0.3-0.7-0.5 c-0.3-0.2-0.6-0.5-0.9-0.7c-0.1-0.1-0.1-0.2,0-0.4l1.2-1.2c0.1-0.1,0.1-0.1,0.2-0.1c0.1,0,0.1,0,0.2,0.1c1,1,1.9,1.5,2.8,1.5 c2.1,0,3.2-1.1,3.2-3.3v-1.4c-0.8,0.7-1.9,1-3.3,1c-1.7,0-3-0.6-4-1.9c-0.8-1.1-1.3-2.5-1.3-4.2c0-1.6,0.4-3,1.2-4.1 c0.9-1.3,2.3-2,4-2c1.3,0,2.4,0.3,3.3,1V6.4c0-0.2,0.1-0.3,0.3-0.3H44c0.2,0,0.3,0.1,0.3,0.3v11.7C44.3,20,43.8,21.5,42.9,22.5z M42,9.9c-0.4-1.1-1.4-1.7-3-1.7c-2,0-3.1,1.3-3.1,3.8c0,1.4,0.3,2.4,1,3.1c0.5,0.5,1.2,0.8,2,0.8c1.6,0,2.7-0.6,3.1-1.7L42,9.9 L42,9.9z&quot;/>\n",
       "              <path d=&quot;M48.3,17.9h-1.8c-0.2,0-0.3-0.1-0.3-0.3V0.3c0-0.2,0.1-0.3,0.3-0.3h1.8c0.2,0,0.3,0.1,0.3,0.3 v17.3C48.5,17.8,48.5,17.9,48.3,17.9z&quot;/>\n",
       "              <path d=&quot;M61.4,12.6c0,0.2-0.1,0.3-0.3,0.3h-8.5c0.1,0.9,0.5,1.6,1.1,2.2c0.7,0.6,1.6,0.9,2.7,0.9 c1,0,1.8-0.3,2.6-0.8c0.2-0.1,0.3-0.1,0.4,0l1.2,1.3c0.1,0.1,0.1,0.3,0,0.4c-1.3,0.9-2.7,1.4-4.4,1.4c-1.8,0-3.3-0.6-4.4-1.8 c-1.1-1.2-1.7-2.7-1.7-4.5c0-1.7,0.6-3.2,1.7-4.4c1-1.1,2.4-1.6,4.1-1.6c1.6,0,2.9,0.6,4,1.7c1.1,1.2,1.6,2.6,1.5,4.4L61.4,12.6 z M58,8.7c-0.6-0.5-1.3-0.8-2.1-0.8c-0.8,0-1.5,0.3-2.1,0.8c-0.6,0.5-1,1.2-1.1,2H59C59,9.9,58.6,9.3,58,8.7z&quot;/>\n",
       "            </g>\n",
       "          </svg>\n",
       "        </a>\n",
       "      `\n",
       "      )`\n",
       "        display: inline-flex;\n",
       "      `;\n",
       "\n",
       "      const Header = styled((props) => {\n",
       "        const { environment } = useContext(Context);\n",
       "\n",
       "        return h`<div className=${props.className} >\n",
       "          <${Logo} />\n",
       "          <span><b>Left / Right Arrow:</b> Increase / Decrease Step</span><span><b>0-9 Row Keys:</b> Playback Speed</span><span><b>Space:</b> Pause / Play</span>\n",
       "          ${environment.title}\n",
       "        </div>`;\n",
       "      })`\n",
       "        align-items: center;\n",
       "        border-bottom: 4px solid #212121;\n",
       "        box-sizing: border-box;\n",
       "        color: #fff;\n",
       "        display: flex;\n",
       "        flex: 0 0 36px;\n",
       "        font-size: 14px;\n",
       "        justify-content: space-between;\n",
       "        padding: 0 8px;\n",
       "        width: 100%;\n",
       "      `;\n",
       "\n",
       "      const Renderer = styled((props) => {\n",
       "        const context = useContext(Context);\n",
       "        const { animate, debug, playing, renderer, speed } = context;\n",
       "        const ref = preact.createRef();\n",
       "\n",
       "        useEffect(async () => {\n",
       "          if (!ref.current) return;\n",
       "\n",
       "          const renderFrame = async (start, step, lastFrame) => {\n",
       "            if (step !== context.step) return;\n",
       "            if (lastFrame === 1) {\n",
       "              if (!animate) return;\n",
       "              start = Date.now();\n",
       "            }\n",
       "            const frame =\n",
       "              playing || animate\n",
       "                ? Math.min((Date.now() - start) / speed, 1)\n",
       "                : 1;\n",
       "            try {\n",
       "              if (debug) console.time(&quot;render&quot;);\n",
       "              await renderer({\n",
       "                ...context,\n",
       "                frame,\n",
       "                height: ref.current.clientHeight,\n",
       "                hooks: preactHooks,\n",
       "                parent: ref.current,\n",
       "                preact,\n",
       "                styled,\n",
       "                width: ref.current.clientWidth,\n",
       "              });\n",
       "            } catch (error) {\n",
       "              if (debug) console.error(error);\n",
       "              console.log({ ...context, frame, error });\n",
       "            } finally {\n",
       "              if (debug) console.timeEnd(&quot;render&quot;);\n",
       "            }\n",
       "            window.requestAnimationFrame(() => renderFrame(start, step, frame));\n",
       "          };\n",
       "\n",
       "          await renderFrame(Date.now(), context.step);\n",
       "        }, [ref.current, context.step, context.renderer]);\n",
       "\n",
       "        return h`<div className=${props.className} ref=${ref} />`;\n",
       "      })`\n",
       "        align-items: center;\n",
       "        box-sizing: border-box;\n",
       "        display: flex;\n",
       "        height: 100%;\n",
       "        left: 0;\n",
       "        justify-content: center;\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        width: 100%;\n",
       "      `;\n",
       "\n",
       "      const Processing = styled((props) => {\n",
       "        const { processing } = useContext(Context);\n",
       "        const text = processing === true ? &quot;Processing...&quot; : processing;\n",
       "        return h`<div className=${props.className}>${text}</div>`;\n",
       "      })`\n",
       "        bottom: 0;\n",
       "        color: #fff;\n",
       "        font-size: 12px;\n",
       "        left: 0;\n",
       "        line-height: 24px;\n",
       "        position: absolute;\n",
       "        text-align: center;\n",
       "        width: 100%;\n",
       "      `;\n",
       "\n",
       "      const Viewer = styled((props) => {\n",
       "        const { processing } = useContext(Context);\n",
       "        return h`<div className=${props.className}>\n",
       "          <${Renderer} />\n",
       "          ${processing && h`<${Processing} />`}\n",
       "        </div>`;\n",
       "      })`\n",
       "        background-color: #000b2a;\n",
       "        background-image: radial-gradient(\n",
       "          circle closest-side,\n",
       "          #000b49,\n",
       "          #000b2a\n",
       "        );\n",
       "        display: flex;\n",
       "        flex: 1;\n",
       "        overflow: hidden;\n",
       "        position: relative;\n",
       "        width: 100%;\n",
       "      `;\n",
       "\n",
       "      // Partitions the elements of arr into subarrays of max length num.\n",
       "      const groupIntoSets = (arr, num) => {\n",
       "        const sets = [];\n",
       "        arr.forEach(a => {\n",
       "          if (sets.length === 0 || sets[sets.length - 1].length === num) {\n",
       "            sets.push([]);\n",
       "          }\n",
       "          sets[sets.length - 1].push(a);\n",
       "        });\n",
       "        return sets;\n",
       "      }\n",
       "\n",
       "      // Expects `width` input prop to set proper max-width for agent name span.\n",
       "      const Legend = styled((props) => {\n",
       "        const { agents, legend } = useContext(Context);\n",
       "\n",
       "        const agentPairs = groupIntoSets(agents.sort((a, b) => a.index - b.index), 2);\n",
       "\n",
       "        return h`<div className=${props.className}>\n",
       "          ${agentPairs.map(agentList =>\n",
       "            h`<ul>\n",
       "                ${agentList.map(a =>\n",
       "                  h`<li key=${a.id} title=&quot;id: ${a.id}&quot; style=&quot;color:${a.color || &quot;#FFF&quot;}&quot;>\n",
       "                      ${a.image && h`<img src=${a.image} />`}\n",
       "                      <span>${a.name}</span>\n",
       "                    </li>`\n",
       "                )}\n",
       "              </ul>`)}\n",
       "        </div>`;\n",
       "      })`\n",
       "        background-color: #000b2a;\n",
       "        font-family: sans-serif;\n",
       "        font-size: 14px;\n",
       "        height: 48px;\n",
       "        width: 100%;\n",
       "\n",
       "        ul {\n",
       "          align-items: center;\n",
       "          display: flex;\n",
       "          flex-direction: row;\n",
       "          justify-content: center;\n",
       "        }\n",
       "\n",
       "        li {\n",
       "          align-items: center;\n",
       "          display: inline-flex;\n",
       "          transition: color 1s;\n",
       "        }\n",
       "\n",
       "        span {\n",
       "          max-width: ${p => (p.width || 400) * 0.5 - 36}px;\n",
       "          overflow: hidden;\n",
       "          text-overflow: ellipsis;\n",
       "          white-space: nowrap;\n",
       "        }\n",
       "\n",
       "        img {\n",
       "          height: 24px;\n",
       "          margin-left: 4px;\n",
       "          margin-right: 4px;\n",
       "          width: 24px;\n",
       "        }\n",
       "      `;\n",
       "\n",
       "      const StepInput = styled.input.attrs({\n",
       "        type: &quot;range&quot;,\n",
       "      })`\n",
       "        appearance: none;\n",
       "        background: rgba(255, 255, 255, 0.15);\n",
       "        border-radius: 2px;\n",
       "        display: block;\n",
       "        flex: 1;\n",
       "        height: 4px;\n",
       "        opacity: 0.8;\n",
       "        outline: none;\n",
       "        transition: opacity 0.2s;\n",
       "        width: 100%;\n",
       "\n",
       "        &:hover {\n",
       "          opacity: 1;\n",
       "        }\n",
       "\n",
       "        &::-webkit-slider-thumb {\n",
       "          appearance: none;\n",
       "          background: #1ebeff;\n",
       "          border-radius: 100%;\n",
       "          cursor: pointer;\n",
       "          height: 12px;\n",
       "          margin: 0;\n",
       "          position: relative;\n",
       "          width: 12px;\n",
       "\n",
       "          &::after {\n",
       "            content: &quot;&quot;;\n",
       "            position: absolute;\n",
       "            top: 0px;\n",
       "            left: 0px;\n",
       "            width: 200px;\n",
       "            height: 8px;\n",
       "            background: green;\n",
       "          }\n",
       "        }\n",
       "      `;\n",
       "\n",
       "      const PlayButton = styled.button`\n",
       "        align-items: center;\n",
       "        background: none;\n",
       "        border: none;\n",
       "        color: white;\n",
       "        cursor: pointer;\n",
       "        display: flex;\n",
       "        flex: 0 0 56px;\n",
       "        font-size: 20px;\n",
       "        height: 40px;\n",
       "        justify-content: center;\n",
       "        opacity: 0.8;\n",
       "        outline: none;\n",
       "        transition: opacity 0.2s;\n",
       "\n",
       "        &:hover {\n",
       "          opacity: 1;\n",
       "        }\n",
       "      `;\n",
       "\n",
       "      const StepCount = styled.span`\n",
       "        align-items: center;\n",
       "        color: white;\n",
       "        display: flex;\n",
       "        font-size: 14px;\n",
       "        justify-content: center;\n",
       "        opacity: 0.8;\n",
       "        padding: 0 16px;\n",
       "        pointer-events: none;\n",
       "      `;\n",
       "\n",
       "      const Controls = styled((props) => {\n",
       "        const { environment, pause, play, playing, setStep, step } = useContext(\n",
       "          Context\n",
       "        );\n",
       "        const value = step + 1;\n",
       "        const onClick = () => (playing ? pause() : play());\n",
       "        const onInput = (e) => {\n",
       "          pause();\n",
       "          setStep(parseInt(e.target.value) - 1);\n",
       "        };\n",
       "\n",
       "        return h`\n",
       "          <div className=${props.className}>\n",
       "            <${PlayButton} onClick=${onClick}><svg xmlns=&quot;http://www.w3.org/2000/svg&quot; width=&quot;24px&quot; height=&quot;24px&quot; viewBox=&quot;0 0 24 24&quot; fill=&quot;#FFFFFF&quot;>${\n",
       "          playing\n",
       "            ? h`<path d=&quot;M6 19h4V5H6v14zm8-14v14h4V5h-4z&quot;/><path d=&quot;M0 0h24v24H0z&quot; fill=&quot;none&quot;/>`\n",
       "            : h`<path d=&quot;M8 5v14l11-7z&quot;/><path d=&quot;M0 0h24v24H0z&quot; fill=&quot;none&quot;/>`\n",
       "        }</svg><//>\n",
       "            <${StepInput} min=&quot;1&quot; max=${\n",
       "          environment.steps.length\n",
       "        } value=&quot;${value}&quot; onInput=${onInput} />\n",
       "            <${StepCount}>${value} / ${environment.steps.length}<//>\n",
       "          </div>\n",
       "        `;\n",
       "      })`\n",
       "        align-items: center;\n",
       "        border-top: 4px solid #212121;\n",
       "        display: flex;\n",
       "        flex: 0 0 44px;\n",
       "        width: 100%;\n",
       "      `;\n",
       "\n",
       "      const Info = styled((props) => {\n",
       "        const {\n",
       "          environment,\n",
       "          playing,\n",
       "          step,\n",
       "          speed,\n",
       "          animate,\n",
       "          header,\n",
       "          controls,\n",
       "          settings,\n",
       "        } = useContext(Context);\n",
       "\n",
       "        return h`\n",
       "          <div className=${props.className}>\n",
       "            info:\n",
       "            step(${step}),\n",
       "            playing(${playing ? &quot;T&quot; : &quot;F&quot;}),\n",
       "            speed(${speed}),\n",
       "            animate(${animate ? &quot;T&quot; : &quot;F&quot;})\n",
       "          </div>`;\n",
       "      })`\n",
       "        color: #888;\n",
       "        font-family: monospace;\n",
       "        font-size: 12px;\n",
       "      `;\n",
       "\n",
       "      const Settings = styled((props) => {\n",
       "        const { environment, pause, play, playing, setStep, step } = useContext(\n",
       "          Context\n",
       "        );\n",
       "\n",
       "        return h`\n",
       "          <div className=${props.className}>\n",
       "            <${Info} />\n",
       "          </div>\n",
       "        `;\n",
       "      })`\n",
       "        background: #fff;\n",
       "        border-top: 4px solid #212121;\n",
       "        box-sizing: border-box;\n",
       "        padding: 20px;\n",
       "        width: 100%;\n",
       "\n",
       "        h1 {\n",
       "          font-size: 20px;\n",
       "        }\n",
       "      `;\n",
       "\n",
       "      const Player = styled((props) => {\n",
       "        const context = useContext(Context);\n",
       "        const { agents, controls, header, legend, loading, settings, width } = context;\n",
       "        return h`\n",
       "          <div className=${props.className}>\n",
       "            ${loading && h`<${Loading} />`}\n",
       "            ${!loading && header && h`<${Header} />`}\n",
       "            ${!loading && h`<${Viewer} />`}\n",
       "            ${!loading && legend && h`<${Legend} width=${width}/>`}\n",
       "            ${!loading && controls && h`<${Controls} />`}\n",
       "            ${!loading && settings && h`<${Settings} />`}\n",
       "          </div>`;\n",
       "      })`\n",
       "        align-items: center;\n",
       "        background: #212121;\n",
       "        border: 4px solid #212121;\n",
       "        box-sizing: border-box;\n",
       "        display: flex;\n",
       "        flex-direction: column;\n",
       "        height: 100%;\n",
       "        justify-content: center;\n",
       "        position: relative;\n",
       "        width: 100%;\n",
       "      `;\n",
       "\n",
       "      const App = () => {\n",
       "        const renderCountRef = useRef(0);\n",
       "        const [_, setRenderCount] = useState(0);\n",
       "\n",
       "        // These are bindings to the 0-9 keys and are milliseconds of timeout per step\n",
       "        const speeds = [\n",
       "          0,\n",
       "          3000,\n",
       "          1000,\n",
       "          500,\n",
       "          333, // Default\n",
       "          200,\n",
       "          100,\n",
       "          50,\n",
       "          25,\n",
       "          10,\n",
       "        ];\n",
       "\n",
       "        const contextRef = useRef({\n",
       "          animate: false,\n",
       "          agents: [],\n",
       "          controls: false,\n",
       "          debug: false,\n",
       "          environment: { steps: [], info: {} },\n",
       "          header: window.innerHeight >= 600,\n",
       "          height: window.innerHeight,\n",
       "          interactive: false,\n",
       "          legend: true,\n",
       "          loading: false,\n",
       "          playing: false,\n",
       "          processing: false,\n",
       "          renderer: () => &quot;DNE&quot;,\n",
       "          settings: false,\n",
       "          speed: speeds[4],\n",
       "          step: 0,\n",
       "          width: window.innerWidth,\n",
       "        });\n",
       "\n",
       "        // Context helpers.\n",
       "        const rerender = (contextRef.current.rerender = () =>\n",
       "          setRenderCount((renderCountRef.current += 1)));\n",
       "        const setStep = (contextRef.current.setStep = (newStep) => {\n",
       "          contextRef.current.step = newStep;\n",
       "          rerender();\n",
       "        });\n",
       "        const setPlaying = (contextRef.current.setPlaying = (playing) => {\n",
       "          contextRef.current.playing = playing;\n",
       "          rerender();\n",
       "        });\n",
       "        const pause = (contextRef.current.pause = () => setPlaying(false));\n",
       "\n",
       "        const playNext = () => {\n",
       "          const context = contextRef.current;\n",
       "\n",
       "          if (\n",
       "            context.playing &&\n",
       "            context.step < context.environment.steps.length - 1\n",
       "          ) {\n",
       "            setStep(context.step + 1);\n",
       "            play(true);\n",
       "          } else {\n",
       "            pause();\n",
       "          }\n",
       "        };\n",
       "\n",
       "        const play = (contextRef.current.play = (continuing) => {\n",
       "          const context = contextRef.current;\n",
       "          if (context.playing && !continuing) return;\n",
       "          if (!context.playing) setPlaying(true);\n",
       "          if (\n",
       "            !continuing &&\n",
       "            context.step === context.environment.steps.length - 1\n",
       "          ) {\n",
       "            setStep(0);\n",
       "          }\n",
       "          setTimeout(playNext, context.speed);\n",
       "        });\n",
       "\n",
       "        const updateContext = (o) => {\n",
       "          const context = contextRef.current;\n",
       "          Object.assign(context, o, {\n",
       "            environment: { ...context.environment, ...(o.environment || {}) },\n",
       "          });\n",
       "          rerender();\n",
       "        };\n",
       "\n",
       "        // First time setup.\n",
       "        useEffect(() => {\n",
       "          // Timeout is used to ensure useEffect renders once.\n",
       "          setTimeout(() => {\n",
       "            // Initialize context with window.kaggle.\n",
       "            updateContext(window.kaggle || {});\n",
       "\n",
       "            if (window.kaggle.playing) {\n",
       "                play(true);\n",
       "            }\n",
       "\n",
       "            // Listen for messages received to update the context.\n",
       "            window.addEventListener(\n",
       "              &quot;message&quot;,\n",
       "              (event) => {\n",
       "                // Ensure the environment names match before updating.\n",
       "                try {\n",
       "                  if (\n",
       "                    event.data.environment.name ==\n",
       "                    contextRef.current.environment.name\n",
       "                  ) {\n",
       "                    updateContext(event.data);\n",
       "                  }\n",
       "                } catch {}\n",
       "              },\n",
       "              false\n",
       "            );\n",
       "            // Listen for keyboard commands.\n",
       "            window.addEventListener(\n",
       "              &quot;keydown&quot;,\n",
       "              (event) => {\n",
       "                const {\n",
       "                  interactive,\n",
       "                  isInteractive,\n",
       "                  playing,\n",
       "                  step,\n",
       "                  environment,\n",
       "                } = contextRef.current;\n",
       "                const key = event.keyCode;\n",
       "                const zero_key = 48\n",
       "                const nine_key = 57\n",
       "                if (\n",
       "                  interactive ||\n",
       "                  isInteractive() ||\n",
       "                  (key !== 32 && key !== 37 && key !== 39 && !(key >= zero_key && key <= nine_key))\n",
       "                )\n",
       "                  return;\n",
       "\n",
       "                if (key === 32) {\n",
       "                  playing ? pause() : play();\n",
       "                } else if (key === 39) {\n",
       "                  contextRef.current.playing = false;\n",
       "                  if (step < environment.steps.length - 1) setStep(step + 1);\n",
       "                  rerender();\n",
       "                } else if (key === 37) {\n",
       "                  contextRef.current.playing = false;\n",
       "                  if (step > 0) setStep(step - 1);\n",
       "                  rerender();\n",
       "                } else if (key >= zero_key && key <= nine_key) {\n",
       "                  contextRef.current.speed = speeds[key - zero_key];\n",
       "                }\n",
       "                event.preventDefault();\n",
       "                return false;\n",
       "              },\n",
       "              false\n",
       "            );\n",
       "          }, 1);\n",
       "        }, []);\n",
       "\n",
       "        if (contextRef.current.debug) {\n",
       "          console.log(&quot;context&quot;, contextRef.current);\n",
       "        }\n",
       "\n",
       "        // Ability to update context.\n",
       "        contextRef.current.update = updateContext;\n",
       "\n",
       "        // Ability to communicate with ipython.\n",
       "        const execute = (contextRef.current.execute = (source) =>\n",
       "          new Promise((resolve, reject) => {\n",
       "            try {\n",
       "              window.parent.IPython.notebook.kernel.execute(source, {\n",
       "                iopub: {\n",
       "                  output: (resp) => {\n",
       "                    const type = resp.msg_type;\n",
       "                    if (type === &quot;stream&quot;) return resolve(resp.content.text);\n",
       "                    if (type === &quot;error&quot;) return reject(new Error(resp.evalue));\n",
       "                    return reject(new Error(&quot;Unknown message type: &quot; + type));\n",
       "                  },\n",
       "                },\n",
       "              });\n",
       "            } catch (e) {\n",
       "              reject(new Error(&quot;IPython Unavailable: &quot; + e));\n",
       "            }\n",
       "          }));\n",
       "\n",
       "        // Ability to return an action from an interactive session.\n",
       "        contextRef.current.act = (action) => {\n",
       "          const id = contextRef.current.environment.id;\n",
       "          updateContext({ processing: true });\n",
       "          execute(`\n",
       "            import json\n",
       "            from kaggle_environments import interactives\n",
       "            if &quot;${id}&quot; in interactives:\n",
       "                action = json.loads('${JSON.stringify(action)}')\n",
       "                env, trainer = interactives[&quot;${id}&quot;]\n",
       "                trainer.step(action)\n",
       "                print(json.dumps(env.steps))`)\n",
       "            .then((resp) => {\n",
       "              try {\n",
       "                updateContext({\n",
       "                  processing: false,\n",
       "                  environment: { steps: JSON.parse(resp) },\n",
       "                });\n",
       "                play();\n",
       "              } catch (e) {\n",
       "                updateContext({ processing: resp.split(&quot;\\n&quot;)[0] });\n",
       "                console.error(resp, e);\n",
       "              }\n",
       "            })\n",
       "            .catch((e) => console.error(e));\n",
       "        };\n",
       "\n",
       "        // Check if currently interactive.\n",
       "        contextRef.current.isInteractive = () => {\n",
       "          const context = contextRef.current;\n",
       "          const steps = context.environment.steps;\n",
       "          return (\n",
       "            context.interactive &&\n",
       "            !context.processing &&\n",
       "            context.step === steps.length - 1 &&\n",
       "            steps[context.step].some((s) => s.status === &quot;ACTIVE&quot;)\n",
       "          );\n",
       "        };\n",
       "\n",
       "        return h`\n",
       "          <${Context.Provider} value=${contextRef.current}>\n",
       "            <${Player} />\n",
       "          <//>`;\n",
       "      };\n",
       "\n",
       "      preact.render(h`<${App} />`, document.body);\n",
       "    </script>\n",
       "  </body>\n",
       "</html>\n",
       "\" width=\"600\" height=\"500\" frameborder=\"0\"></iframe> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 测试 agent\n",
    "env = make(\"connectx\", debug=True)\n",
    "env.run([agent_random, agent_random])\n",
    "env.render(mode=\"ipython\", width=600, height=500, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
